{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiara import KiaraAPI, Kiara\n",
    "import networkx\n",
    "from networkx.readwrite import json_graph\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all (global) variables that will be used in this notebook\n",
    "\n",
    "# the folder this notebook lives in\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# the onboarding pipeline, defined in 'corpus_onboarding.yaml' in the 'pipelines' folder\n",
    "onboarding_pipeline = os.path.join(current_path, 'pipelines', 'corpus_onboarding.yaml')\n",
    "# the onboarding pipeline, defined in 'topic_modeling.yaml' in the 'pipelines' folder\n",
    "topic_modeling_pipeline = os.path.join(current_path, 'pipelines', 'topic_modeling.yaml')\n",
    "\n",
    "\n",
    "# the local path to example dataset, the defaults is located in the `example_data/mini_corpus` folder next to this notebook\n",
    "# change to a different one by adjusting the following variable, e.g.:\n",
    "# corpus_path = '/Users/mariella.decrouychan/Documents/GitHub/kiara_plugin.playground/examples/data/CI_newspaper_subcorpora'\n",
    "corpus_path = os.path.join(current_path, 'example_data', 'mini_corpus')\n",
    "\n",
    "# the general alias related to the current data prep (to be able to easily spot data created now in data registry)\n",
    "gen_alias = 'test5oct22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api = KiaraAPI.instance(\"topic_modeling\")\n",
    "api = KiaraAPI.instance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: kiara\n",
      "Version: 0.4.21\n",
      "Summary: Data-centric workflow orchestration.\n",
      "Home-page: https://github.com/DHARPA-Project/kiara\n",
      "Author: Markus Binsteiner\n",
      "Author-email: markus@frkl.io\n",
      "License: MPL-2.0\n",
      "Location: /opt/miniconda3/envs/lineage2/lib/python3.10/site-packages\n",
      "Requires: airium, alembic, appdirs, bidict, black, click, dag-cbor, deepdiff, Deprecated, distro, dpath, filetype, humanfriendly, jinja2, jupytext, mistune, mkdocstrings, mmh3, multiformats, networkx, orjson, pp-ez, pydantic, python-dateutil, python-slugify, pyzmq, regex, rich, rich-click, ruamel.yaml, sortedcontainers, sqlalchemy, sqlalchemy-utc, sqlalchemy-utils, stevedore, structlog, textual, tzlocal\n",
      "Required-by: kiara-plugin.core-types, kiara-plugin.tabular\n"
     ]
    }
   ],
   "source": [
    "# version of Kiara used in this notebook\n",
    "!pip show kiara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Overview of the operations we will be experimenting on to create lineage data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- corpus onboarding\n",
    "example corpus onboarding pipeline from https://github.com/DHARPA-Project/DHARPA-Project-viz-observable/blob/main/dag-lineage/pipelines/corpus_onboarding.yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                                            \n",
       " <span style=\"font-style: italic\"> Documentation </span>  Onboard a text corpus.                                                                                                    \n",
       "                                                                                                                                            \n",
       " <span style=\"font-style: italic\"> Inputs        </span>                                                                                                                            \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-weight: bold\"> field name              </span> <span style=\"font-weight: bold\"> type    </span> <span style=\"font-weight: bold\"> description                       </span> <span style=\"font-weight: bold\"> Required </span> <span style=\"font-weight: bold\"> Default                           </span>   \n",
       " <span style=\"font-style: italic\">               </span>   ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────   \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> text_corpus_folder_path </span>  string    The local path of the folder to     no         /home/markus/projects/kiara_new/…    \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\">                         </span>            import.                                                                             \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> filename_column_name    </span>  string    The name of the column to           no         file_name                            \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\">                         </span>            extract.                                                                            \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> force_parsed_date       </span>  boolean   If set to 'True', raise an error    no         True                                 \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\">                         </span>            if any of the strings in the                                                        \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\">                         </span>            array can't be parsed.                                                              \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> date_parse_min          </span>  integer   The minimum index from where to     no         11                                   \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\">                         </span>            start parsing the string(s).                                                        \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> date_parse_max          </span>  integer   The maximum index until whic to     no         21                                   \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\">                         </span>            parse the string(s).                                                                \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> remove_tokens           </span>  list      A list of tokens/characters to      no         []                                   \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\">                         </span>            replace with a single white-space                                                   \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\">                         </span>            before parsing the input.                                                           \n",
       " <span style=\"font-style: italic\">               </span>                                                                                                                            \n",
       "                                                                                                                                            \n",
       " <span style=\"font-style: italic\"> Outputs       </span>                                                                                                                            \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-weight: bold\"> field name   </span> <span style=\"font-weight: bold\"> type  </span> <span style=\"font-weight: bold\"> description                                                                                   </span>   \n",
       " <span style=\"font-style: italic\">               </span>   ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────   \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> corpus_table </span>  table   The merged table, including all source tables and columns.                                       \n",
       " <span style=\"font-style: italic\">               </span>                                                                                                                            \n",
       "                                                                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                                                                                                                            \n",
       " \u001b[3m \u001b[0m\u001b[3mDocumentation\u001b[0m\u001b[3m \u001b[0m  Onboard a text corpus.                                                                                                    \n",
       "                                                                                                                                            \n",
       " \u001b[3m \u001b[0m\u001b[3mInputs       \u001b[0m\u001b[3m \u001b[0m                                                                                                                            \n",
       " \u001b[3m               \u001b[0m   \u001b[1m \u001b[0m\u001b[1mfield name             \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mtype   \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mdescription                      \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRequired\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDefault                          \u001b[0m\u001b[1m \u001b[0m   \n",
       " \u001b[3m               \u001b[0m   ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────   \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mtext_corpus_folder_path\u001b[0m\u001b[3m \u001b[0m  string    The local path of the folder to     no         /home/markus/projects/kiara_new/…    \n",
       " \u001b[3m               \u001b[0m   \u001b[3m                         \u001b[0m            import.                                                                             \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mfilename_column_name   \u001b[0m\u001b[3m \u001b[0m  string    The name of the column to           no         file_name                            \n",
       " \u001b[3m               \u001b[0m   \u001b[3m                         \u001b[0m            extract.                                                                            \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mforce_parsed_date      \u001b[0m\u001b[3m \u001b[0m  boolean   If set to 'True', raise an error    no         True                                 \n",
       " \u001b[3m               \u001b[0m   \u001b[3m                         \u001b[0m            if any of the strings in the                                                        \n",
       " \u001b[3m               \u001b[0m   \u001b[3m                         \u001b[0m            array can't be parsed.                                                              \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mdate_parse_min         \u001b[0m\u001b[3m \u001b[0m  integer   The minimum index from where to     no         11                                   \n",
       " \u001b[3m               \u001b[0m   \u001b[3m                         \u001b[0m            start parsing the string(s).                                                        \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mdate_parse_max         \u001b[0m\u001b[3m \u001b[0m  integer   The maximum index until whic to     no         21                                   \n",
       " \u001b[3m               \u001b[0m   \u001b[3m                         \u001b[0m            parse the string(s).                                                                \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mremove_tokens          \u001b[0m\u001b[3m \u001b[0m  list      A list of tokens/characters to      no         []                                   \n",
       " \u001b[3m               \u001b[0m   \u001b[3m                         \u001b[0m            replace with a single white-space                                                   \n",
       " \u001b[3m               \u001b[0m   \u001b[3m                         \u001b[0m            before parsing the input.                                                           \n",
       " \u001b[3m               \u001b[0m                                                                                                                            \n",
       "                                                                                                                                            \n",
       " \u001b[3m \u001b[0m\u001b[3mOutputs      \u001b[0m\u001b[3m \u001b[0m                                                                                                                            \n",
       " \u001b[3m               \u001b[0m   \u001b[1m \u001b[0m\u001b[1mfield name  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mtype \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mdescription                                                                                  \u001b[0m\u001b[1m \u001b[0m   \n",
       " \u001b[3m               \u001b[0m   ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────   \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mcorpus_table\u001b[0m\u001b[3m \u001b[0m  table   The merged table, including all source tables and columns.                                       \n",
       " \u001b[3m               \u001b[0m                                                                                                                            \n",
       "                                                                                                                                            \n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onboarding_op = api.get_operation(onboarding_pipeline, allow_external=True)\n",
    "onboarding_op                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- text processing\n",
    "example topic modeling pipeline from https://github.com/DHARPA-Project/DHARPA-Project-viz-observable/blob/main/dag-lineage/pipelines/topic_modeling.yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                                            \n",
       " <span style=\"font-style: italic\"> Documentation </span>  Topic-modeling of a provided corpus table dataset.                                                                        \n",
       "                                                                                                                                            \n",
       " <span style=\"font-style: italic\"> Inputs        </span>                                                                                                                            \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-weight: bold\"> field name          </span> <span style=\"font-weight: bold\"> type    </span> <span style=\"font-weight: bold\"> description                                            </span> <span style=\"font-weight: bold\"> Required </span> <span style=\"font-weight: bold\"> Default          </span>   \n",
       " <span style=\"font-style: italic\">               </span>   ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────   \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> corpus              </span>  table     A table.                                                 <span style=\"font-weight: bold\">yes</span>        -- no default --    \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> tokenize_by_word    </span>  boolean   Whether to tokenize by word (default), or character.     no         True                \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> languages           </span>  list      A list of languages, will be used to retrieve            no         ['italian']         \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\">                     </span>            language-specific stopword from nltk.                                                   \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> stopword_lists      </span>  list      A list of lists of stopwords.                            no         []                  \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> to_lowercase        </span>  boolean   Apply lowercasing to the text.                           no         False               \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> remove_alphanumeric </span>  boolean   Remove all tokens that include numbers (e.g.             no         False               \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\">                     </span>            ex1ample).                                                                              \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> remove_non_alpha    </span>  boolean   Remove all tokens that include punctuation and numbers   no         False               \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\">                     </span>            (e.g. ex1a.mple).                                                                       \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> remove_all_numeric  </span>  boolean   Remove all tokens that contain numbers only (e.g.        no         False               \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\">                     </span>            876).                                                                                   \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> remove_short_tokens </span>  integer   Remove tokens shorter than a certain length. If value    no         False               \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\">                     </span>            is &lt;= 0, no filtering will be done.                                                     \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> num_topics_min      </span>  integer   The minimal number of topics.                            no         7                   \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> num_topics_max      </span>  integer   The max number of topics.                                no         9                   \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> compute_coherence   </span>  boolean   Whether to compute the coherence score for each model.   no         True                \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> words_per_topic     </span>  integer   How many words per topic to put in the result model.     no         10                  \n",
       " <span style=\"font-style: italic\">               </span>                                                                                                                            \n",
       "                                                                                                                                            \n",
       " <span style=\"font-style: italic\"> Outputs       </span>                                                                                                                            \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-weight: bold\"> field name          </span> <span style=\"font-weight: bold\"> type  </span> <span style=\"font-weight: bold\"> description                                                                            </span>   \n",
       " <span style=\"font-style: italic\">               </span>   ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────   \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> content_array       </span>  array   The column.                                                                               \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> tokenized_corpus    </span>  array   The tokenized content, as an array of lists of strings.                                   \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> preprocessed_corpus </span>  array   The pre-processed content, as an array of lists of strings.                               \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> topic_models        </span>  dict    A dictionary with one coherence model table for each number of topics.                    \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> coherence_table     </span>  table   Coherence details.                                                                        \n",
       " <span style=\"font-style: italic\">               </span>   <span style=\"font-style: italic\"> coherence_map       </span>  dict    A map with the coherence value for every number of topics.                                \n",
       " <span style=\"font-style: italic\">               </span>                                                                                                                            \n",
       "                                                                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                                                                                                                            \n",
       " \u001b[3m \u001b[0m\u001b[3mDocumentation\u001b[0m\u001b[3m \u001b[0m  Topic-modeling of a provided corpus table dataset.                                                                        \n",
       "                                                                                                                                            \n",
       " \u001b[3m \u001b[0m\u001b[3mInputs       \u001b[0m\u001b[3m \u001b[0m                                                                                                                            \n",
       " \u001b[3m               \u001b[0m   \u001b[1m \u001b[0m\u001b[1mfield name         \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mtype   \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mdescription                                           \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRequired\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDefault         \u001b[0m\u001b[1m \u001b[0m   \n",
       " \u001b[3m               \u001b[0m   ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────   \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mcorpus             \u001b[0m\u001b[3m \u001b[0m  table     A table.                                                 \u001b[1myes\u001b[0m        -- no default --    \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mtokenize_by_word   \u001b[0m\u001b[3m \u001b[0m  boolean   Whether to tokenize by word (default), or character.     no         True                \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mlanguages          \u001b[0m\u001b[3m \u001b[0m  list      A list of languages, will be used to retrieve            no         ['italian']         \n",
       " \u001b[3m               \u001b[0m   \u001b[3m                     \u001b[0m            language-specific stopword from nltk.                                                   \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mstopword_lists     \u001b[0m\u001b[3m \u001b[0m  list      A list of lists of stopwords.                            no         []                  \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mto_lowercase       \u001b[0m\u001b[3m \u001b[0m  boolean   Apply lowercasing to the text.                           no         False               \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mremove_alphanumeric\u001b[0m\u001b[3m \u001b[0m  boolean   Remove all tokens that include numbers (e.g.             no         False               \n",
       " \u001b[3m               \u001b[0m   \u001b[3m                     \u001b[0m            ex1ample).                                                                              \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mremove_non_alpha   \u001b[0m\u001b[3m \u001b[0m  boolean   Remove all tokens that include punctuation and numbers   no         False               \n",
       " \u001b[3m               \u001b[0m   \u001b[3m                     \u001b[0m            (e.g. ex1a.mple).                                                                       \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mremove_all_numeric \u001b[0m\u001b[3m \u001b[0m  boolean   Remove all tokens that contain numbers only (e.g.        no         False               \n",
       " \u001b[3m               \u001b[0m   \u001b[3m                     \u001b[0m            876).                                                                                   \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mremove_short_tokens\u001b[0m\u001b[3m \u001b[0m  integer   Remove tokens shorter than a certain length. If value    no         False               \n",
       " \u001b[3m               \u001b[0m   \u001b[3m                     \u001b[0m            is <= 0, no filtering will be done.                                                     \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mnum_topics_min     \u001b[0m\u001b[3m \u001b[0m  integer   The minimal number of topics.                            no         7                   \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mnum_topics_max     \u001b[0m\u001b[3m \u001b[0m  integer   The max number of topics.                                no         9                   \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mcompute_coherence  \u001b[0m\u001b[3m \u001b[0m  boolean   Whether to compute the coherence score for each model.   no         True                \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mwords_per_topic    \u001b[0m\u001b[3m \u001b[0m  integer   How many words per topic to put in the result model.     no         10                  \n",
       " \u001b[3m               \u001b[0m                                                                                                                            \n",
       "                                                                                                                                            \n",
       " \u001b[3m \u001b[0m\u001b[3mOutputs      \u001b[0m\u001b[3m \u001b[0m                                                                                                                            \n",
       " \u001b[3m               \u001b[0m   \u001b[1m \u001b[0m\u001b[1mfield name         \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mtype \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mdescription                                                                           \u001b[0m\u001b[1m \u001b[0m   \n",
       " \u001b[3m               \u001b[0m   ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────   \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mcontent_array      \u001b[0m\u001b[3m \u001b[0m  array   The column.                                                                               \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mtokenized_corpus   \u001b[0m\u001b[3m \u001b[0m  array   The tokenized content, as an array of lists of strings.                                   \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mpreprocessed_corpus\u001b[0m\u001b[3m \u001b[0m  array   The pre-processed content, as an array of lists of strings.                               \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mtopic_models       \u001b[0m\u001b[3m \u001b[0m  dict    A dictionary with one coherence model table for each number of topics.                    \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mcoherence_table    \u001b[0m\u001b[3m \u001b[0m  table   Coherence details.                                                                        \n",
       " \u001b[3m               \u001b[0m   \u001b[3m \u001b[0m\u001b[3mcoherence_map      \u001b[0m\u001b[3m \u001b[0m  dict    A map with the coherence value for every number of topics.                                \n",
       " \u001b[3m               \u001b[0m                                                                                                                            \n",
       "                                                                                                                                            \n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_modeling_op = api.get_operation(topic_modeling_pipeline, allow_external=True)\n",
    "topic_modeling_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Lineage data for the onboarding step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data onboarding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_result = api.run_job(operation=onboarding_op, inputs={'text_corpus_folder_path': corpus_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StoreValueResult(value=Value(id=88037481-de5d-4df2-b7d1-0e405aa648f1, type=table, status=set, initialized=True optional=False), aliases=['tm_test5oct22_onboard'], persisted_data=PersistedData(model_id=zdpuAxPin6TsfMCtxHYfmPXujaY8AqcLgKG87vHrmfYKbvRbv, category=instance.persisted_data, fields=[data_type, data_type_config, serialization_profile, metadata, hash_codec, archive_id, chunk_id_map]), error=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = onboarding_result[\"corpus_table\"]\n",
    "api.store_value(table, f'tm_{gen_alias}_onboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "╭─ Available aliases ──────────────────────────────────────────────────────────╮\n",
      "│                                                                              │\n",
      "│  \u001b[1m \u001b[0m\u001b[1malias                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mtype \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1m     size\u001b[0m\u001b[1m \u001b[0m                                 │\n",
      "│  ───────────────────────────────────────────                                 │\n",
      "│   tm_test5oct22_onboard   table   300.77 KB                                  │\n",
      "│                                                                              │\n",
      "╰──────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    }
   ],
   "source": [
    "# checking how that would appear in CLI\n",
    "! kiara data list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lineage data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_table = api.get_value(value='tm_test5oct22_onboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = corpus_table.lineage.module_graph\n",
    "result = json_graph.node_link_data(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'directed': True,\n",
       " 'multigraph': False,\n",
       " 'graph': {},\n",
       " 'nodes': [{'data_type': 'table',\n",
       "   'label': '[this value]',\n",
       "   'node_type': 'value',\n",
       "   'data_type_config': {},\n",
       "   'level': 1,\n",
       "   'id': 'value:88037481-de5d-4df2-b7d1-0e405aa648f1'},\n",
       "  {'module_type': 'table.merge',\n",
       "   'module_config': {'constants': {},\n",
       "    'defaults': {},\n",
       "    'inputs_schema': {'source_table': {'type': 'table',\n",
       "      'type_config': {},\n",
       "      'default': '__not_set__',\n",
       "      'optional': False,\n",
       "      'is_constant': False,\n",
       "      'doc': {'description': 'The original table.', 'doc': None}},\n",
       "     'date_array': {'type': 'array',\n",
       "      'type_config': {},\n",
       "      'default': '__not_set__',\n",
       "      'optional': False,\n",
       "      'is_constant': False,\n",
       "      'doc': {'description': 'The array containing the parsed date items.',\n",
       "       'doc': None}}},\n",
       "    'column_map': {'date': 'date_array',\n",
       "     'content': 'source_table.content',\n",
       "     'file_name': 'source_table.file_name'}},\n",
       "   'label': 'table.merge',\n",
       "   'node_type': 'operation',\n",
       "   'level': 3,\n",
       "   'id': 'module:zdpuAzybdPqAwszJEtqjGgiafHHk2y6bVLerT1TfUFkhk94xV'},\n",
       "  {'module_type': 'parse.date_array',\n",
       "   'module_config': {'constants': {},\n",
       "    'defaults': {},\n",
       "    'add_inputs': True,\n",
       "    'input_fields': [],\n",
       "    'force_non_null': True,\n",
       "    'min_index': None,\n",
       "    'max_index': None,\n",
       "    'remove_tokens': []},\n",
       "   'label': 'parse.date_array',\n",
       "   'node_type': 'operation',\n",
       "   'level': 5,\n",
       "   'id': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4'},\n",
       "  {'module_type': 'table.cut_column',\n",
       "   'module_config': {'constants': {}, 'defaults': {}},\n",
       "   'label': 'table.cut_column',\n",
       "   'node_type': 'operation',\n",
       "   'level': 7,\n",
       "   'id': 'module:zdpuB19zscMvy4C9ETug9tGkHsTZ3a3N9FHY8htZS1UaPCX3c'},\n",
       "  {'label': 'column_name (string)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'string',\n",
       "   'data_type_config': {},\n",
       "   'level': 8,\n",
       "   'id': 'value:0b8ee78f-921f-4479-b2d1-1e760f826875'},\n",
       "  {'module_type': 'create.table',\n",
       "   'module_config': {'constants': {},\n",
       "    'defaults': {},\n",
       "    'source_type': 'text_file_bundle',\n",
       "    'target_type': 'table',\n",
       "    'ignore_errors': False},\n",
       "   'label': 'create.table',\n",
       "   'node_type': 'operation',\n",
       "   'level': 5,\n",
       "   'id': 'module:zdpuAkfC7c35pp8SAfCx7Xmk1G1RQMvEymq4mvjDk47e1H9XN'},\n",
       "  {'module_type': 'import.file_bundle',\n",
       "   'module_config': {'constants': {}, 'defaults': {}},\n",
       "   'label': 'import.file_bundle',\n",
       "   'node_type': 'operation',\n",
       "   'level': 7,\n",
       "   'id': 'module:zdpuAvtJAAff57xASJxvSmQ6w7SRS9W4wPQfUVftGcZAjtQdD'},\n",
       "  {'label': 'path (string)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'string',\n",
       "   'data_type_config': {},\n",
       "   'level': 8,\n",
       "   'id': 'value:1d1776f3-239f-4db7-b3dd-7d408bcd0302'},\n",
       "  {'label': 'force_non_null (boolean)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'boolean',\n",
       "   'data_type_config': {},\n",
       "   'level': 6,\n",
       "   'id': 'value:195805cd-bdda-45d5-abb3-968fc5d3bfd5'},\n",
       "  {'label': 'max_index (integer)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'integer',\n",
       "   'data_type_config': {},\n",
       "   'level': 6,\n",
       "   'id': 'value:9bf6c998-9d8b-4571-ac92-a7e3d8d87892'},\n",
       "  {'label': 'min_index (integer)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'integer',\n",
       "   'data_type_config': {},\n",
       "   'level': 6,\n",
       "   'id': 'value:ebfb1534-cef9-400c-9fdb-59c5d2f6302f'},\n",
       "  {'label': 'remove_tokens (list)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'list',\n",
       "   'data_type_config': {},\n",
       "   'level': 6,\n",
       "   'id': 'value:c6b4f1c4-a9c4-4e32-96cc-301e223fc1f9'}],\n",
       " 'links': [{'id': 'value:88037481-de5d-4df2-b7d1-0e405aa648f1:module:zdpuAzybdPqAwszJEtqjGgiafHHk2y6bVLerT1TfUFkhk94xV',\n",
       "   'field_name': 'table',\n",
       "   'label': 'table (table)',\n",
       "   'source': 'module:zdpuAzybdPqAwszJEtqjGgiafHHk2y6bVLerT1TfUFkhk94xV',\n",
       "   'target': 'value:88037481-de5d-4df2-b7d1-0e405aa648f1'},\n",
       "  {'id': 'module:zdpuAzybdPqAwszJEtqjGgiafHHk2y6bVLerT1TfUFkhk94xV:date_array',\n",
       "   'field_name': 'date_array',\n",
       "   'label': 'date_array (array)',\n",
       "   'source': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4',\n",
       "   'target': 'module:zdpuAzybdPqAwszJEtqjGgiafHHk2y6bVLerT1TfUFkhk94xV'},\n",
       "  {'id': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4:array',\n",
       "   'field_name': 'array',\n",
       "   'label': 'array (array)',\n",
       "   'source': 'module:zdpuB19zscMvy4C9ETug9tGkHsTZ3a3N9FHY8htZS1UaPCX3c',\n",
       "   'target': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4'},\n",
       "  {'id': 'module:zdpuB19zscMvy4C9ETug9tGkHsTZ3a3N9FHY8htZS1UaPCX3c:value:0b8ee78f-921f-4479-b2d1-1e760f826875',\n",
       "   'field_name': 'column_name',\n",
       "   'label': 'column_name (string)',\n",
       "   'source': 'value:0b8ee78f-921f-4479-b2d1-1e760f826875',\n",
       "   'target': 'module:zdpuB19zscMvy4C9ETug9tGkHsTZ3a3N9FHY8htZS1UaPCX3c'},\n",
       "  {'id': 'module:zdpuAzybdPqAwszJEtqjGgiafHHk2y6bVLerT1TfUFkhk94xV:source_table',\n",
       "   'field_name': 'source_table',\n",
       "   'label': 'source_table (table)',\n",
       "   'source': 'module:zdpuAkfC7c35pp8SAfCx7Xmk1G1RQMvEymq4mvjDk47e1H9XN',\n",
       "   'target': 'module:zdpuAzybdPqAwszJEtqjGgiafHHk2y6bVLerT1TfUFkhk94xV'},\n",
       "  {'id': 'module:zdpuB19zscMvy4C9ETug9tGkHsTZ3a3N9FHY8htZS1UaPCX3c:table',\n",
       "   'field_name': 'table',\n",
       "   'label': 'table (table)',\n",
       "   'source': 'module:zdpuAkfC7c35pp8SAfCx7Xmk1G1RQMvEymq4mvjDk47e1H9XN',\n",
       "   'target': 'module:zdpuB19zscMvy4C9ETug9tGkHsTZ3a3N9FHY8htZS1UaPCX3c'},\n",
       "  {'id': 'module:zdpuAkfC7c35pp8SAfCx7Xmk1G1RQMvEymq4mvjDk47e1H9XN:text_file_bundle',\n",
       "   'field_name': 'text_file_bundle',\n",
       "   'label': 'text_file_bundle (file_bundle)',\n",
       "   'source': 'module:zdpuAvtJAAff57xASJxvSmQ6w7SRS9W4wPQfUVftGcZAjtQdD',\n",
       "   'target': 'module:zdpuAkfC7c35pp8SAfCx7Xmk1G1RQMvEymq4mvjDk47e1H9XN'},\n",
       "  {'id': 'module:zdpuAvtJAAff57xASJxvSmQ6w7SRS9W4wPQfUVftGcZAjtQdD:value:1d1776f3-239f-4db7-b3dd-7d408bcd0302',\n",
       "   'field_name': 'path',\n",
       "   'label': 'path (string)',\n",
       "   'source': 'value:1d1776f3-239f-4db7-b3dd-7d408bcd0302',\n",
       "   'target': 'module:zdpuAvtJAAff57xASJxvSmQ6w7SRS9W4wPQfUVftGcZAjtQdD'},\n",
       "  {'id': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4:value:195805cd-bdda-45d5-abb3-968fc5d3bfd5',\n",
       "   'field_name': 'force_non_null',\n",
       "   'label': 'force_non_null (boolean)',\n",
       "   'source': 'value:195805cd-bdda-45d5-abb3-968fc5d3bfd5',\n",
       "   'target': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4'},\n",
       "  {'id': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4:value:9bf6c998-9d8b-4571-ac92-a7e3d8d87892',\n",
       "   'field_name': 'max_index',\n",
       "   'label': 'max_index (integer)',\n",
       "   'source': 'value:9bf6c998-9d8b-4571-ac92-a7e3d8d87892',\n",
       "   'target': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4'},\n",
       "  {'id': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4:value:ebfb1534-cef9-400c-9fdb-59c5d2f6302f',\n",
       "   'field_name': 'min_index',\n",
       "   'label': 'min_index (integer)',\n",
       "   'source': 'value:ebfb1534-cef9-400c-9fdb-59c5d2f6302f',\n",
       "   'target': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4'},\n",
       "  {'id': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4:value:c6b4f1c4-a9c4-4e32-96cc-301e223fc1f9',\n",
       "   'field_name': 'remove_tokens',\n",
       "   'label': 'remove_tokens (list)',\n",
       "   'source': 'value:c6b4f1c4-a9c4-4e32-96cc-301e223fc1f9',\n",
       "   'target': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = graph.nodes.data()\n",
    "augmented_nodes = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'value:c6b4f1c4-a9c4-4e32-96cc-301e223fc1f9',\n",
       " 'desc': {'label': 'remove_tokens (list)',\n",
       "  'node_type': 'value',\n",
       "  'data_type': 'list',\n",
       "  'data_type_config': {},\n",
       "  'level': 6},\n",
       " 'parentIds': [],\n",
       " 'info': {'preview': \"list_data=[] item_schema={'title': 'list', 'type': 'object'} python_class=PythonClass(model_id=list, category=instance.wrapped_python_class, fields=[python_class_name, python_module_name, full_name])\"}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_info(node):\n",
    "    # all this is terribly inefficient\n",
    "    if node[1][\"node_type\"] == \"operation\":\n",
    "        result = api.retrieve_module_type_info(node[1][\"module_type\"]).dict()\n",
    "    elif node[1][\"node_type\"] == \"value\":\n",
    "        value_id = node[0][6:]\n",
    "        v = api.get_value(value_id)\n",
    "\n",
    "        render_result = api.render_value(value=v, target_format=\"string\").rendered\n",
    "\n",
    "        result = {\n",
    "            \"preview\": render_result\n",
    "        }\n",
    "    return result\n",
    "\n",
    "for idx, node in enumerate(nodes):\n",
    "    node_dict = {\n",
    "        \"id\": node[0],\n",
    "        \"desc\": node[1],\n",
    "        \"parentIds\": [pred for pred in graph.predecessors(node[0])],\n",
    "        \"info\": get_info(node)\n",
    "    }\n",
    "    augmented_nodes[idx] = node_dict\n",
    "node_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'id': 'value:88037481-de5d-4df2-b7d1-0e405aa648f1',\n",
       "  'desc': {'data_type': 'table',\n",
       "   'label': '[this value]',\n",
       "   'node_type': 'value',\n",
       "   'data_type_config': {},\n",
       "   'level': 1},\n",
       "  'parentIds': ['module:zdpuAzybdPqAwszJEtqjGgiafHHk2y6bVLerT1TfUFkhk94xV'],\n",
       "  'info': {'preview': \"date\\tcontent\\tfile_name\\t\\n1917-04-25 00:00:00\\tLA RAGIONE\\tsn84037024_1917-04-25_ed-1_seq-1_ocr.txt\\t\\n1917-04-25 00:00:00\\tLA RAG ONE\\tsn84037024_1917-04-25_ed-2_seq-1_ocr.txt\\t\\n1917-04-25 00:00:00\\tLA RAGIONE\\tsn84037024_1917-04-25_ed-3_seq-1_ocr.txt\\t\\n1917-04-25 00:00:00\\tcontro i vili, i camorristi, i sicari, i falsari e gli austriacanti, nemici della patria di e di quella d adozione.\\tsn84037024_1917-04-25_ed-4_seq-1_ocr.txt\\t\\n1917-05-05 00:00:00\\tcontro i vili, i camorristi, i sicari, i falsari e gli austriacanti, nemici della patria di origine e di quella d' adozione\\tsn84037024_1917-05-05_ed-1_seq-1_ocr.txt\\t\\n1917-05-05 00:00:00\\tLA RAGIONA\\tsn84037024_1917-05-05_ed-2_seq-1_ocr.txt\\t\\n1917-05-05 00:00:00\\tLA RAGIONE\\tsn84037024_1917-05-05_ed-3_seq-1_ocr.txt\\t\\n1917-05-05 00:00:00\\tLA RAGIONE\\tsn84037024_1917-05-05_ed-4_seq-1_ocr.txt\\t\\n1917-05-16 00:00:00\\tcontro i vili, i camorristi, i sicari, i falsari e gli austriacanti, nemici della patria di origine e di quella d'adozione\\tsn84037024_1917-05-16_ed-1_seq-1_ocr.txt\\t\\n1917-05-16 00:00:00\\tLA RAG ONE\\tsn84037024_1917-05-16_ed-2_seq-1_ocr.txt\\t\\n1917-05-16 00:00:00\\tcontro 1 vili, i camorristi, i sicari, i falsari e gli austriacanti, nemici della patria di origine e di quella d'adozione.\\tsn84037024_1917-05-16_ed-3_seq-1_ocr.txt\\t\\n1917-04-07 00:00:00\\t■■■\\tsn84037025_1917-04-07_ed-1_seq-1_ocr.txt\\t\\n1917-04-14 00:00:00\\tLa Rassegna\\tsn84037025_1917-04-14_ed-1_seq-1_ocr.txt\\t\\n1917-04-14 00:00:00\\tBoth Phones\\tsn84037025_1917-04-14_ed-2_seq-1_ocr.txt\\t\\n1917-04-21 00:00:00\\t■ jSrìt** W?? iIK 38®f- i^M\\tsn84037025_1917-04-21_ed-1_seq-1_ocr.txt\\t\\n1917-04-21 00:00:00\\t■Both Phones\\tsn84037025_1917-04-21_ed-2_seq-1_ocr.txt\\t\\n\"}},\n",
       " 1: {'id': 'module:zdpuAzybdPqAwszJEtqjGgiafHHk2y6bVLerT1TfUFkhk94xV',\n",
       "  'desc': {'module_type': 'table.merge',\n",
       "   'module_config': {'constants': {},\n",
       "    'defaults': {},\n",
       "    'inputs_schema': {'source_table': {'type': 'table',\n",
       "      'type_config': {},\n",
       "      'default': '__not_set__',\n",
       "      'optional': False,\n",
       "      'is_constant': False,\n",
       "      'doc': {'description': 'The original table.', 'doc': None}},\n",
       "     'date_array': {'type': 'array',\n",
       "      'type_config': {},\n",
       "      'default': '__not_set__',\n",
       "      'optional': False,\n",
       "      'is_constant': False,\n",
       "      'doc': {'description': 'The array containing the parsed date items.',\n",
       "       'doc': None}}},\n",
       "    'column_map': {'date': 'date_array',\n",
       "     'content': 'source_table.content',\n",
       "     'file_name': 'source_table.file_name'}},\n",
       "   'label': 'table.merge',\n",
       "   'node_type': 'operation',\n",
       "   'level': 3},\n",
       "  'parentIds': ['module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4',\n",
       "   'module:zdpuAkfC7c35pp8SAfCx7Xmk1G1RQMvEymq4mvjDk47e1H9XN'],\n",
       "  'info': {'type_name': 'table.merge',\n",
       "   'documentation': {'description': 'Create a table from other tables and/or arrays.',\n",
       "    'doc': \"This module needs configuration to be set (for now). It's currently not possible to merge an arbitrary\\nnumber of tables/arrays, all tables to be merged must be specified in the module configuration.\\n\\nColumn names of the resulting table can be controlled by the 'column_map' configuration, which takes the\\ndesired column name as key, and a field-name in the following format as value:\\n- '[inputs_schema key]' for inputs of type 'array'\\n- '[inputs_schema_key].orig_column_name' for inputs of type 'table'\"},\n",
       "   'authors': {'authors': [{'name': 'Markus Binsteiner',\n",
       "      'email': 'markus@frkl.io'}]},\n",
       "   'context': {'references': {'source_repo': {'url': AnyUrl('https://github.com/DHARPA-Project/kiara_plugin.tabular', scheme='https', host='github.com', tld='com', host_type='domain', path='/DHARPA-Project/kiara_plugin.tabular'),\n",
       "      'desc': 'The module package git repository.'},\n",
       "     'documentation': {'url': AnyUrl('https://DHARPA-Project.github.io/kiara_plugin.tabular/', scheme='https', host='DHARPA-Project.github.io', tld='io', host_type='domain', path='/kiara_plugin.tabular/'),\n",
       "      'desc': 'The url for the module package documentation.'}},\n",
       "    'tags': ['tabular'],\n",
       "    'labels': {'package': 'kiara_plugin.tabular'}},\n",
       "   'python_class': {'python_class_name': 'MergeTableModule',\n",
       "    'python_module_name': 'kiara_plugin.tabular.modules.table',\n",
       "    'full_name': 'kiara_plugin.tabular.modules.table.MergeTableModule'},\n",
       "   'process_src': 'def process(self, inputs: ValueMap, outputs: ValueMap, job_log: JobLog) -> None:\\n\\n    import pyarrow as pa\\n\\n    inputs_schema: Dict[str, Any] = self.get_config_value(\"inputs_schema\")\\n    column_map: Dict[str, str] = self.get_config_value(\"column_map\")\\n\\n    sources = {}\\n    for field_name in inputs_schema.keys():\\n        sources[field_name] = inputs.get_value_data(field_name)\\n\\n    len_dict = {}\\n    arrays = {}\\n\\n    column_map_final = dict(column_map)\\n\\n    for source_key, table_or_array in sources.items():\\n\\n        if isinstance(table_or_array, KiaraTable):\\n            rows = table_or_array.num_rows\\n            for name in table_or_array.column_names:\\n                array_name = f\"{source_key}.{name}\"\\n                if column_map and array_name not in column_map.values():\\n                    job_log.add_log(\\n                        f\"Ignoring column \\'{name}\\' of input table \\'{source_key}\\': not listed in column_map.\"\\n                    )\\n                    continue\\n\\n                column = table_or_array.arrow_table.column(name)\\n                arrays[array_name] = column\\n                if not column_map:\\n                    if name in column_map_final:\\n                        raise Exception(\\n                            f\"Can\\'t merge table, duplicate column name: {name}.\"\\n                        )\\n                    column_map_final[name] = array_name\\n\\n        elif isinstance(table_or_array, KiaraArray):\\n\\n            if column_map and source_key not in column_map.values():\\n                job_log.add_log(\\n                    f\"Ignoring array \\'{source_key}\\': not listed in column_map.\"\\n                )\\n                continue\\n\\n            rows = len(table_or_array)\\n            arrays[source_key] = table_or_array.arrow_array\\n\\n            if not column_map:\\n                if source_key in column_map_final.keys():\\n                    raise Exception(\\n                        f\"Can\\'t merge table, duplicate column name: {source_key}.\"\\n                    )\\n                column_map_final[source_key] = source_key\\n\\n        else:\\n            raise KiaraProcessingException(\\n                f\"Can\\'t merge table: invalid type \\'{type(table_or_array)}\\' for source \\'{source_key}\\'.\"\\n            )\\n\\n        len_dict[source_key] = rows\\n\\n    all_rows = None\\n    for source_key, rows in len_dict.items():\\n        if all_rows is None:\\n            all_rows = rows\\n        else:\\n            if all_rows != rows:\\n                all_rows = None\\n                break\\n\\n    if all_rows is None:\\n        len_str = \"\"\\n        for name, rows in len_dict.items():\\n            len_str = f\" {name} ({rows})\"\\n\\n        raise KiaraProcessingException(\\n            f\"Can\\'t merge table, sources have different lengths: {len_str}\"\\n        )\\n\\n    column_names = []\\n    columns = []\\n    for column_name, ref in column_map_final.items():\\n        column_names.append(column_name)\\n        column = arrays[ref]\\n        columns.append(column)\\n\\n    table = pa.Table.from_arrays(arrays=columns, names=column_names)\\n\\n    outputs.set_value(\"table\", table)\\n',\n",
       "   'config': {'python_class': {'python_class_name': 'MergeTableConfig',\n",
       "     'python_module_name': 'kiara_plugin.tabular.modules.table',\n",
       "     'full_name': 'kiara_plugin.tabular.modules.table.MergeTableConfig'},\n",
       "    'config_values': {'constants': {'description': 'Value constants for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'defaults': {'description': 'Value defaults for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'inputs_schema': {'description': 'A dict describing the inputs for this merge process.',\n",
       "      'type': 'object',\n",
       "      'value_default': None,\n",
       "      'required': True},\n",
       "     'column_map': {'description': 'A map describing',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False}}}}},\n",
       " 2: {'id': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4',\n",
       "  'desc': {'module_type': 'parse.date_array',\n",
       "   'module_config': {'constants': {},\n",
       "    'defaults': {},\n",
       "    'add_inputs': True,\n",
       "    'input_fields': [],\n",
       "    'force_non_null': True,\n",
       "    'min_index': None,\n",
       "    'max_index': None,\n",
       "    'remove_tokens': []},\n",
       "   'label': 'parse.date_array',\n",
       "   'node_type': 'operation',\n",
       "   'level': 5},\n",
       "  'parentIds': ['module:zdpuB19zscMvy4C9ETug9tGkHsTZ3a3N9FHY8htZS1UaPCX3c',\n",
       "   'value:195805cd-bdda-45d5-abb3-968fc5d3bfd5',\n",
       "   'value:9bf6c998-9d8b-4571-ac92-a7e3d8d87892',\n",
       "   'value:ebfb1534-cef9-400c-9fdb-59c5d2f6302f',\n",
       "   'value:c6b4f1c4-a9c4-4e32-96cc-301e223fc1f9'],\n",
       "  'info': {'type_name': 'parse.date_array',\n",
       "   'documentation': {'description': 'Create an array of date objects from an array of strings.',\n",
       "    'doc': \"This module is very simplistic at the moment, more functionality and options will be added in the future.\\n\\nAt its core, this module uses the standard parser from the\\n[dateutil](https://github.com/dateutil/dateutil) package to parse strings into dates. As this parser can't handle\\n complex strings, the input strings can be pre-processed in the following ways:\\n\\n- 'cut' non-relevant parts of the string (using 'min_index' & 'max_index' input/config options)\\n- remove matching tokens from the string, and replace them with a single whitespace (using the 'remove_tokens' option)\\n\\nBy default, if an input string can't be parsed this module will raise an exception. This can be prevented by\\nsetting this modules 'force_non_null' config option or input to 'False', in which case un-parsable strings\\nwill appear as 'NULL' value in the resulting array.\"},\n",
       "   'authors': {'authors': [{'name': 'Markus Binsteiner',\n",
       "      'email': 'markus@frkl.io'}]},\n",
       "   'context': {'references': {'source_repo': {'url': AnyUrl('https://github.com/DHARPA-Project/kiara_plugin.tabular', scheme='https', host='github.com', tld='com', host_type='domain', path='/DHARPA-Project/kiara_plugin.tabular'),\n",
       "      'desc': 'The module package git repository.'},\n",
       "     'documentation': {'url': AnyUrl('https://DHARPA-Project.github.io/kiara_plugin.tabular/', scheme='https', host='DHARPA-Project.github.io', tld='io', host_type='domain', path='/kiara_plugin.tabular/'),\n",
       "      'desc': 'The url for the module package documentation.'}},\n",
       "    'tags': ['tabular'],\n",
       "    'labels': {'package': 'kiara_plugin.tabular'}},\n",
       "   'python_class': {'python_class_name': 'ExtractDateModule',\n",
       "    'python_module_name': 'kiara_plugin.tabular.modules.array',\n",
       "    'full_name': 'kiara_plugin.tabular.modules.array.ExtractDateModule'},\n",
       "   'process_src': 'def process(self, inputs: ValueMap, outputs: ValueMap, job_log: JobLog):\\n\\n    import polars as pl\\n    import pyarrow as pa\\n    from dateutil import parser\\n\\n    force_non_null: bool = self.get_data_for_field(\\n        field_name=\"force_non_null\", inputs=inputs\\n    )\\n    min_pos: Union[None, int] = self.get_data_for_field(\\n        field_name=\"min_index\", inputs=inputs\\n    )\\n    if min_pos is None:\\n        min_pos = 0\\n    max_pos: Union[None, int] = self.get_data_for_field(\\n        field_name=\"max_index\", inputs=inputs\\n    )\\n    remove_tokens: Iterable[str] = self.get_data_for_field(\\n        field_name=\"remove_tokens\", inputs=inputs\\n    )\\n\\n    def parse_date(_text: str):\\n\\n        text = _text\\n        if min_pos:\\n            try:\\n                text = text[min_pos:]  # type: ignore\\n            except Exception:\\n                return None\\n        if max_pos:\\n            try:\\n                text = text[0 : max_pos - min_pos]  # type: ignore  # noqa\\n            except Exception:\\n                pass\\n\\n        if remove_tokens:\\n            for t in remove_tokens:\\n                text = text.replace(t, \" \")\\n\\n        try:\\n            d_obj = parser.parse(text, fuzzy=True)\\n        except Exception as e:\\n            if force_non_null:\\n                raise KiaraProcessingException(e)\\n            return None\\n\\n        if d_obj is None:\\n            if force_non_null:\\n                raise KiaraProcessingException(\\n                    f\"Can\\'t parse date from string: {text}\"\\n                )\\n            return None\\n\\n        return d_obj\\n\\n    value = inputs.get_value_obj(\"array\")\\n    array: KiaraArray = value.data\\n\\n    series = pl.Series(name=\"tokens\", values=array.arrow_array)\\n    job_log.add_log(f\"start parsing date for {len(array)} items\")\\n    result = series.apply(parse_date)\\n    job_log.add_log(f\"finished parsing date for {len(array)} items\")\\n    result_array = result.to_arrow()\\n\\n    # TODO: remove this cast once the array data type can handle non-chunked arrays\\n    chunked = pa.chunked_array(result_array)\\n    outputs.set_values(date_array=chunked)\\n',\n",
       "   'config': {'python_class': {'python_class_name': 'ExtractDateConfig',\n",
       "     'python_module_name': 'kiara_plugin.tabular.modules.array',\n",
       "     'full_name': 'kiara_plugin.tabular.modules.array.ExtractDateConfig'},\n",
       "    'config_values': {'constants': {'description': 'Value constants for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'defaults': {'description': 'Value defaults for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'add_inputs': {'description': \"If set to 'True', parse options will be available as inputs.\",\n",
       "      'type': 'boolean',\n",
       "      'value_default': True,\n",
       "      'required': False},\n",
       "     'input_fields': {'description': 'If not empty, only add the fields specified in here to the module inputs schema.',\n",
       "      'type': 'array',\n",
       "      'value_default': [],\n",
       "      'required': False},\n",
       "     'force_non_null': {'description': \"If set to 'True', raise an error if any of the strings in the array can't be parsed.\",\n",
       "      'type': 'boolean',\n",
       "      'value_default': True,\n",
       "      'required': False},\n",
       "     'min_index': {'description': 'The minimum index from where to start parsing the string(s).',\n",
       "      'type': 'integer',\n",
       "      'value_default': None,\n",
       "      'required': False},\n",
       "     'max_index': {'description': 'The maximum index until whic to parse the string(s).',\n",
       "      'type': 'integer',\n",
       "      'value_default': None,\n",
       "      'required': False},\n",
       "     'remove_tokens': {'description': 'A list of tokens/characters to replace with a single white-space before parsing the input.',\n",
       "      'type': 'array',\n",
       "      'value_default': [],\n",
       "      'required': False}}}}},\n",
       " 3: {'id': 'module:zdpuB19zscMvy4C9ETug9tGkHsTZ3a3N9FHY8htZS1UaPCX3c',\n",
       "  'desc': {'module_type': 'table.cut_column',\n",
       "   'module_config': {'constants': {}, 'defaults': {}},\n",
       "   'label': 'table.cut_column',\n",
       "   'node_type': 'operation',\n",
       "   'level': 7},\n",
       "  'parentIds': ['value:0b8ee78f-921f-4479-b2d1-1e760f826875',\n",
       "   'module:zdpuAkfC7c35pp8SAfCx7Xmk1G1RQMvEymq4mvjDk47e1H9XN'],\n",
       "  'info': {'type_name': 'table.cut_column',\n",
       "   'documentation': {'description': 'Cut off one column from a table, returning an array.',\n",
       "    'doc': None},\n",
       "   'authors': {'authors': [{'name': 'Markus Binsteiner',\n",
       "      'email': 'markus@frkl.io'}]},\n",
       "   'context': {'references': {'source_repo': {'url': AnyUrl('https://github.com/DHARPA-Project/kiara_plugin.tabular', scheme='https', host='github.com', tld='com', host_type='domain', path='/DHARPA-Project/kiara_plugin.tabular'),\n",
       "      'desc': 'The module package git repository.'},\n",
       "     'documentation': {'url': AnyUrl('https://DHARPA-Project.github.io/kiara_plugin.tabular/', scheme='https', host='DHARPA-Project.github.io', tld='io', host_type='domain', path='/kiara_plugin.tabular/'),\n",
       "      'desc': 'The url for the module package documentation.'}},\n",
       "    'tags': ['tabular'],\n",
       "    'labels': {'package': 'kiara_plugin.tabular'}},\n",
       "   'python_class': {'python_class_name': 'CutColumnModule',\n",
       "    'python_module_name': 'kiara_plugin.tabular.modules.table',\n",
       "    'full_name': 'kiara_plugin.tabular.modules.table.CutColumnModule'},\n",
       "   'process_src': 'def process(self, inputs: ValueMap, outputs: ValueMap) -> None:\\n\\n    import pyarrow as pa\\n\\n    column_name: str = inputs.get_value_data(\"column_name\")\\n\\n    table_value: Value = inputs.get_value_obj(\"table\")\\n    table_metadata: KiaraTableMetadata = table_value.get_property_data(\\n        \"metadata.table\"\\n    )\\n\\n    available = table_metadata.table.column_names\\n\\n    if column_name not in available:\\n        raise KiaraProcessingException(\\n            f\"Invalid column name \\'{column_name}\\'. Available column names: {\\', \\'.join(available)}\"\\n        )\\n\\n    table: pa.Table = table_value.data.arrow_table\\n    column = table.column(column_name)\\n\\n    outputs.set_value(\"array\", column)\\n',\n",
       "   'config': {'python_class': {'python_class_name': 'KiaraModuleConfig',\n",
       "     'python_module_name': 'kiara.models.module',\n",
       "     'full_name': 'kiara.models.module.KiaraModuleConfig'},\n",
       "    'config_values': {'constants': {'description': 'Value constants for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'defaults': {'description': 'Value defaults for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False}}}}},\n",
       " 4: {'id': 'value:0b8ee78f-921f-4479-b2d1-1e760f826875',\n",
       "  'desc': {'label': 'column_name (string)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'string',\n",
       "   'data_type_config': {},\n",
       "   'level': 8},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': 'file_name'}},\n",
       " 5: {'id': 'module:zdpuAkfC7c35pp8SAfCx7Xmk1G1RQMvEymq4mvjDk47e1H9XN',\n",
       "  'desc': {'module_type': 'create.table',\n",
       "   'module_config': {'constants': {},\n",
       "    'defaults': {},\n",
       "    'source_type': 'text_file_bundle',\n",
       "    'target_type': 'table',\n",
       "    'ignore_errors': False},\n",
       "   'label': 'create.table',\n",
       "   'node_type': 'operation',\n",
       "   'level': 5},\n",
       "  'parentIds': ['module:zdpuAvtJAAff57xASJxvSmQ6w7SRS9W4wPQfUVftGcZAjtQdD'],\n",
       "  'info': {'type_name': 'create.table',\n",
       "   'documentation': {'description': '-- n/a --', 'doc': None},\n",
       "   'authors': {'authors': [{'name': 'Markus Binsteiner',\n",
       "      'email': 'markus@frkl.io'}]},\n",
       "   'context': {'references': {'source_repo': {'url': AnyUrl('https://github.com/DHARPA-Project/kiara_plugin.tabular', scheme='https', host='github.com', tld='com', host_type='domain', path='/DHARPA-Project/kiara_plugin.tabular'),\n",
       "      'desc': 'The module package git repository.'},\n",
       "     'documentation': {'url': AnyUrl('https://DHARPA-Project.github.io/kiara_plugin.tabular/', scheme='https', host='DHARPA-Project.github.io', tld='io', host_type='domain', path='/kiara_plugin.tabular/'),\n",
       "      'desc': 'The url for the module package documentation.'}},\n",
       "    'tags': ['tabular'],\n",
       "    'labels': {'package': 'kiara_plugin.tabular'}},\n",
       "   'python_class': {'python_class_name': 'CreateTableModule',\n",
       "    'python_module_name': 'kiara_plugin.tabular.modules.table',\n",
       "    'full_name': 'kiara_plugin.tabular.modules.table.CreateTableModule'},\n",
       "   'process_src': 'def process(self, inputs: ValueMap, outputs: ValueMap) -> None:\\n\\n    source_type = self.get_config_value(\"source_type\")\\n    target_type = self.get_config_value(\"target_type\")\\n\\n    func_name = f\"create__{target_type}__from__{source_type}\"\\n    func = getattr(self, func_name)\\n\\n    source_value = inputs.get_value_obj(source_type)\\n\\n    signature = inspect.signature(func)\\n    if \"optional\" in signature.parameters:\\n        optional: Dict[str, Value] = {}\\n        op_schemas = {}\\n        for field, schema in self.inputs_schema.items():\\n            if field == source_type:\\n                continue\\n            optional[field] = inputs.get_value_obj(field)\\n            op_schemas[field] = schema\\n        result = func(\\n            source_value=source_value,\\n            optional=ValueMapReadOnly(\\n                value_items=optional, values_schema=op_schemas\\n            ),\\n        )\\n    else:\\n        result = func(source_value=source_value)\\n    outputs.set_value(target_type, result)\\n',\n",
       "   'config': {'python_class': {'python_class_name': 'CreateTableModuleConfig',\n",
       "     'python_module_name': 'kiara_plugin.tabular.modules.table',\n",
       "     'full_name': 'kiara_plugin.tabular.modules.table.CreateTableModuleConfig'},\n",
       "    'config_values': {'constants': {'description': 'Value constants for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'defaults': {'description': 'Value defaults for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'source_type': {'description': 'The value type of the source value.',\n",
       "      'type': 'string',\n",
       "      'value_default': None,\n",
       "      'required': True},\n",
       "     'target_type': {'description': 'The value type of the target.',\n",
       "      'type': 'string',\n",
       "      'value_default': None,\n",
       "      'required': True},\n",
       "     'ignore_errors': {'description': 'Whether to ignore convert errors and omit the failed items.',\n",
       "      'type': 'boolean',\n",
       "      'value_default': False,\n",
       "      'required': False}}}}},\n",
       " 6: {'id': 'module:zdpuAvtJAAff57xASJxvSmQ6w7SRS9W4wPQfUVftGcZAjtQdD',\n",
       "  'desc': {'module_type': 'import.file_bundle',\n",
       "   'module_config': {'constants': {}, 'defaults': {}},\n",
       "   'label': 'import.file_bundle',\n",
       "   'node_type': 'operation',\n",
       "   'level': 7},\n",
       "  'parentIds': ['value:1d1776f3-239f-4db7-b3dd-7d408bcd0302'],\n",
       "  'info': {'type_name': 'import.file_bundle',\n",
       "   'documentation': {'description': 'Import a folder (file_bundle) from the local filesystem.',\n",
       "    'doc': None},\n",
       "   'authors': {'authors': [{'name': 'Markus Binsteiner',\n",
       "      'email': 'markus@frkl.io'}]},\n",
       "   'context': {'references': {'source_repo': {'url': AnyUrl('https://github.com/DHARPA-Project/kiara', scheme='https', host='github.com', tld='com', host_type='domain', path='/DHARPA-Project/kiara'),\n",
       "      'desc': 'The kiara project git repository.'},\n",
       "     'documentation': {'url': AnyUrl('https://dharpa.org/kiara_documentation/', scheme='https', host='dharpa.org', tld='org', host_type='domain', path='/kiara_documentation/'),\n",
       "      'desc': 'The url for kiara documentation.'}},\n",
       "    'tags': [],\n",
       "    'labels': {'package': 'kiara'}},\n",
       "   'python_class': {'python_class_name': 'ImportFileBundleModule',\n",
       "    'python_module_name': 'kiara.modules.included_core_modules.filesystem',\n",
       "    'full_name': 'kiara.modules.included_core_modules.filesystem.ImportFileBundleModule'},\n",
       "   'process_src': 'def process(self, inputs: ValueMap, outputs: ValueMap):\\n\\n    path = inputs.get_value_data(\"path\")\\n\\n    file_bundle = FileBundle.import_folder(source=path)\\n    outputs.set_value(\"file_bundle\", file_bundle)\\n',\n",
       "   'config': {'python_class': {'python_class_name': 'KiaraModuleConfig',\n",
       "     'python_module_name': 'kiara.models.module',\n",
       "     'full_name': 'kiara.models.module.KiaraModuleConfig'},\n",
       "    'config_values': {'constants': {'description': 'Value constants for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'defaults': {'description': 'Value defaults for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False}}}}},\n",
       " 7: {'id': 'value:1d1776f3-239f-4db7-b3dd-7d408bcd0302',\n",
       "  'desc': {'label': 'path (string)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'string',\n",
       "   'data_type_config': {},\n",
       "   'level': 8},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': '/Users/mariella.decrouychan/Documents/GitHub/DHARPA-Project-viz-observable/dag-lineage/example_data/mini_corpus'}},\n",
       " 8: {'id': 'value:195805cd-bdda-45d5-abb3-968fc5d3bfd5',\n",
       "  'desc': {'label': 'force_non_null (boolean)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'boolean',\n",
       "   'data_type_config': {},\n",
       "   'level': 6},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': 'True'}},\n",
       " 9: {'id': 'value:9bf6c998-9d8b-4571-ac92-a7e3d8d87892',\n",
       "  'desc': {'label': 'max_index (integer)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'integer',\n",
       "   'data_type_config': {},\n",
       "   'level': 6},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': '21'}},\n",
       " 10: {'id': 'value:ebfb1534-cef9-400c-9fdb-59c5d2f6302f',\n",
       "  'desc': {'label': 'min_index (integer)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'integer',\n",
       "   'data_type_config': {},\n",
       "   'level': 6},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': '11'}},\n",
       " 11: {'id': 'value:c6b4f1c4-a9c4-4e32-96cc-301e223fc1f9',\n",
       "  'desc': {'label': 'remove_tokens (list)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'list',\n",
       "   'data_type_config': {},\n",
       "   'level': 6},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': \"list_data=[] item_schema={'title': 'list', 'type': 'object'} python_class=PythonClass(model_id=list, category=instance.wrapped_python_class, fields=[python_class_name, python_module_name, full_name])\"}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to export dataset for the viz\n",
    "\n",
    "# res = json.dumps(augmented_nodes)\n",
    "# with open(\"lineage_data_1.json\", \"w\") as outfile:\n",
    "#     outfile.write(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Lineage data for nlp step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- running the example TM pipeline with previously onboarded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_step = api.run_job(operation=topic_modeling_op, inputs={'corpus': corpus_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StoreValueResult(value=Value(id=fe802251-d595-4f09-869a-71e67eca18f1, type=dict, status=set, initialized=True optional=False), aliases=['tm_test5oct22_coherence_map'], persisted_data=PersistedData(model_id=zdpuApg4H742soUdpA3iLmsPmb5koxkcinR2VPkjG3vfg5J5j, category=instance.persisted_data, fields=[data_type, data_type_config, serialization_profile, metadata, hash_codec, archive_id, chunk_id_map]), error=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_corpus = nlp_step[\"coherence_map\"]\n",
    "api.store_value(preprocessed_corpus, f'tm_{gen_alias}_coherence_map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "╭─ Available aliases ──────────────────────────────────────────────────────────╮\n",
      "│                                                                              │\n",
      "│  \u001b[1m \u001b[0m\u001b[1malias                            \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mtype \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1m     size\u001b[0m\u001b[1m \u001b[0m                     │\n",
      "│  ───────────────────────────────────────────────────────                     │\n",
      "│   tm_test5oct22_coherence_map         dict    228 bytes                      │\n",
      "│   tm_test5oct22_onboard               table   300.77 KB                      │\n",
      "│   tm_test5oct22_preprocessed_corpus   array   489.27 KB                      │\n",
      "│                                                                              │\n",
      "╰──────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    }
   ],
   "source": [
    "!kiara data list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lineage data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is not really necessary, since the 'preprocessed_corpus' variable still holds that value\n",
    "preprocessed_corpus = api.get_value(value='tm_test5oct22_coherence_map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = preprocessed_corpus.lineage.module_graph\n",
    "result = json_graph.node_link_data(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'directed': True,\n",
       " 'multigraph': False,\n",
       " 'graph': {},\n",
       " 'nodes': [{'data_type': 'dict',\n",
       "   'label': '[this value]',\n",
       "   'node_type': 'value',\n",
       "   'data_type_config': {},\n",
       "   'level': 1,\n",
       "   'id': 'value:fe802251-d595-4f09-869a-71e67eca18f1'},\n",
       "  {'module_type': 'generate.LDA.for.tokens_array',\n",
       "   'module_config': {'constants': {}, 'defaults': {}},\n",
       "   'label': 'generate.LDA.for.tokens_array',\n",
       "   'node_type': 'operation',\n",
       "   'level': 3,\n",
       "   'id': 'module:zdpuAoRTS61Hf3P8nNJFAy1ryxbHQmwjC7K2qpr21X5fRM19t'},\n",
       "  {'label': 'tokenize_by_word (boolean)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'boolean',\n",
       "   'data_type_config': {},\n",
       "   'level': 8,\n",
       "   'id': 'value:195805cd-bdda-45d5-abb3-968fc5d3bfd5'},\n",
       "  {'label': 'num_topics_max (integer)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'integer',\n",
       "   'data_type_config': {},\n",
       "   'level': 4,\n",
       "   'id': 'value:d68fb5ef-1c43-4aef-8957-3f7f1f7e6de0'},\n",
       "  {'label': 'num_topics_min (integer)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'integer',\n",
       "   'data_type_config': {},\n",
       "   'level': 4,\n",
       "   'id': 'value:a6454c4e-2605-444d-bff9-b7e8d184091e'},\n",
       "  {'module_type': 'preprocess.tokens_array',\n",
       "   'module_config': {'constants': {}, 'defaults': {}},\n",
       "   'label': 'preprocess.tokens_array',\n",
       "   'node_type': 'operation',\n",
       "   'level': 5,\n",
       "   'id': 'module:zdpuAqYPUdxbgJK3PxJe7iMDjrDhnNDA2P2ZcpbKc7HNpyPwf'},\n",
       "  {'label': 'to_lowercase (boolean)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'boolean',\n",
       "   'data_type_config': {},\n",
       "   'level': 6,\n",
       "   'id': 'value:c1c95ddb-31a4-472b-bb89-cd070edbb182'},\n",
       "  {'label': 'remove_short_tokens (integer)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'integer',\n",
       "   'data_type_config': {},\n",
       "   'level': 6,\n",
       "   'id': 'value:7959e49b-a2b9-4446-84ff-624a1479710a'},\n",
       "  {'module_type': 'create.stopwords_list',\n",
       "   'module_config': {'constants': {}, 'defaults': {}},\n",
       "   'label': 'create.stopwords_list',\n",
       "   'node_type': 'operation',\n",
       "   'level': 7,\n",
       "   'id': 'module:zdpuAyow1kztfmcrG3aEeKgk4dgDRNh946qzZxX5uN9z3K4w8'},\n",
       "  {'label': 'languages (list)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'list',\n",
       "   'data_type_config': {},\n",
       "   'level': 8,\n",
       "   'id': 'value:aa5230e0-f7df-451d-b8de-756e30dda42b'},\n",
       "  {'label': 'remove_tokens (list)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'list',\n",
       "   'data_type_config': {},\n",
       "   'level': 14,\n",
       "   'id': 'value:c6b4f1c4-a9c4-4e32-96cc-301e223fc1f9'},\n",
       "  {'module_type': 'tokenize.texts_array',\n",
       "   'module_config': {'constants': {}, 'defaults': {}},\n",
       "   'label': 'tokenize.texts_array',\n",
       "   'node_type': 'operation',\n",
       "   'level': 7,\n",
       "   'id': 'module:zdpuApN9LQPHc9PKSDp3UmCBdFXYhYMEgPmMbRkhQbKAGWCGa'},\n",
       "  {'module_type': 'table.cut_column',\n",
       "   'module_config': {'constants': {'column_name': 'content'}, 'defaults': {}},\n",
       "   'label': 'table.cut_column',\n",
       "   'node_type': 'operation',\n",
       "   'level': 9,\n",
       "   'id': 'module:zdpuB1emJxNaL5cYnQ8zEvRaq2azadRPeoQaSqR4eXKE7Up4h'},\n",
       "  {'label': 'column_name (string)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'string',\n",
       "   'data_type_config': {},\n",
       "   'level': 10,\n",
       "   'id': 'value:61f3241e-f423-4052-93b2-d50887f6c76b'},\n",
       "  {'module_type': 'table.merge',\n",
       "   'module_config': {'constants': {},\n",
       "    'defaults': {},\n",
       "    'inputs_schema': {'source_table': {'type': 'table',\n",
       "      'type_config': {},\n",
       "      'default': '__not_set__',\n",
       "      'optional': False,\n",
       "      'is_constant': False,\n",
       "      'doc': {'description': 'The original table.', 'doc': None}},\n",
       "     'date_array': {'type': 'array',\n",
       "      'type_config': {},\n",
       "      'default': '__not_set__',\n",
       "      'optional': False,\n",
       "      'is_constant': False,\n",
       "      'doc': {'description': 'The array containing the parsed date items.',\n",
       "       'doc': None}}},\n",
       "    'column_map': {'date': 'date_array',\n",
       "     'content': 'source_table.content',\n",
       "     'file_name': 'source_table.file_name'}},\n",
       "   'label': 'table.merge',\n",
       "   'node_type': 'operation',\n",
       "   'level': 11,\n",
       "   'id': 'module:zdpuAzybdPqAwszJEtqjGgiafHHk2y6bVLerT1TfUFkhk94xV'},\n",
       "  {'module_type': 'parse.date_array',\n",
       "   'module_config': {'constants': {},\n",
       "    'defaults': {},\n",
       "    'add_inputs': True,\n",
       "    'input_fields': [],\n",
       "    'force_non_null': True,\n",
       "    'min_index': None,\n",
       "    'max_index': None,\n",
       "    'remove_tokens': []},\n",
       "   'label': 'parse.date_array',\n",
       "   'node_type': 'operation',\n",
       "   'level': 13,\n",
       "   'id': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4'},\n",
       "  {'module_type': 'table.cut_column',\n",
       "   'module_config': {'constants': {}, 'defaults': {}},\n",
       "   'label': 'table.cut_column',\n",
       "   'node_type': 'operation',\n",
       "   'level': 15,\n",
       "   'id': 'module:zdpuB19zscMvy4C9ETug9tGkHsTZ3a3N9FHY8htZS1UaPCX3c'},\n",
       "  {'label': 'column_name (string)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'string',\n",
       "   'data_type_config': {},\n",
       "   'level': 16,\n",
       "   'id': 'value:0b8ee78f-921f-4479-b2d1-1e760f826875'},\n",
       "  {'module_type': 'create.table',\n",
       "   'module_config': {'constants': {},\n",
       "    'defaults': {},\n",
       "    'source_type': 'text_file_bundle',\n",
       "    'target_type': 'table',\n",
       "    'ignore_errors': False},\n",
       "   'label': 'create.table',\n",
       "   'node_type': 'operation',\n",
       "   'level': 13,\n",
       "   'id': 'module:zdpuAkfC7c35pp8SAfCx7Xmk1G1RQMvEymq4mvjDk47e1H9XN'},\n",
       "  {'module_type': 'import.file_bundle',\n",
       "   'module_config': {'constants': {}, 'defaults': {}},\n",
       "   'label': 'import.file_bundle',\n",
       "   'node_type': 'operation',\n",
       "   'level': 15,\n",
       "   'id': 'module:zdpuAvtJAAff57xASJxvSmQ6w7SRS9W4wPQfUVftGcZAjtQdD'},\n",
       "  {'label': 'path (string)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'string',\n",
       "   'data_type_config': {},\n",
       "   'level': 16,\n",
       "   'id': 'value:1d1776f3-239f-4db7-b3dd-7d408bcd0302'},\n",
       "  {'label': 'max_index (integer)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'integer',\n",
       "   'data_type_config': {},\n",
       "   'level': 14,\n",
       "   'id': 'value:9bf6c998-9d8b-4571-ac92-a7e3d8d87892'},\n",
       "  {'label': 'min_index (integer)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'integer',\n",
       "   'data_type_config': {},\n",
       "   'level': 14,\n",
       "   'id': 'value:ebfb1534-cef9-400c-9fdb-59c5d2f6302f'},\n",
       "  {'label': 'words_per_topic (integer)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'integer',\n",
       "   'data_type_config': {},\n",
       "   'level': 4,\n",
       "   'id': 'value:5704a550-4f4c-44b2-95f3-bf25364a41ee'}],\n",
       " 'links': [{'id': 'value:fe802251-d595-4f09-869a-71e67eca18f1:module:zdpuAoRTS61Hf3P8nNJFAy1ryxbHQmwjC7K2qpr21X5fRM19t',\n",
       "   'field_name': 'coherence_map',\n",
       "   'label': 'coherence_map (dict)',\n",
       "   'source': 'module:zdpuAoRTS61Hf3P8nNJFAy1ryxbHQmwjC7K2qpr21X5fRM19t',\n",
       "   'target': 'value:fe802251-d595-4f09-869a-71e67eca18f1'},\n",
       "  {'id': 'module:zdpuAoRTS61Hf3P8nNJFAy1ryxbHQmwjC7K2qpr21X5fRM19t:value:195805cd-bdda-45d5-abb3-968fc5d3bfd5',\n",
       "   'field_name': 'compute_coherence',\n",
       "   'label': 'compute_coherence (boolean)',\n",
       "   'source': 'value:195805cd-bdda-45d5-abb3-968fc5d3bfd5',\n",
       "   'target': 'module:zdpuAoRTS61Hf3P8nNJFAy1ryxbHQmwjC7K2qpr21X5fRM19t'},\n",
       "  {'id': 'module:zdpuApN9LQPHc9PKSDp3UmCBdFXYhYMEgPmMbRkhQbKAGWCGa:value:195805cd-bdda-45d5-abb3-968fc5d3bfd5',\n",
       "   'field_name': 'tokenize_by_word',\n",
       "   'label': 'tokenize_by_word (boolean)',\n",
       "   'source': 'value:195805cd-bdda-45d5-abb3-968fc5d3bfd5',\n",
       "   'target': 'module:zdpuApN9LQPHc9PKSDp3UmCBdFXYhYMEgPmMbRkhQbKAGWCGa'},\n",
       "  {'id': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4:value:195805cd-bdda-45d5-abb3-968fc5d3bfd5',\n",
       "   'field_name': 'force_non_null',\n",
       "   'label': 'force_non_null (boolean)',\n",
       "   'source': 'value:195805cd-bdda-45d5-abb3-968fc5d3bfd5',\n",
       "   'target': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4'},\n",
       "  {'id': 'module:zdpuAoRTS61Hf3P8nNJFAy1ryxbHQmwjC7K2qpr21X5fRM19t:value:d68fb5ef-1c43-4aef-8957-3f7f1f7e6de0',\n",
       "   'field_name': 'num_topics_max',\n",
       "   'label': 'num_topics_max (integer)',\n",
       "   'source': 'value:d68fb5ef-1c43-4aef-8957-3f7f1f7e6de0',\n",
       "   'target': 'module:zdpuAoRTS61Hf3P8nNJFAy1ryxbHQmwjC7K2qpr21X5fRM19t'},\n",
       "  {'id': 'module:zdpuAoRTS61Hf3P8nNJFAy1ryxbHQmwjC7K2qpr21X5fRM19t:value:a6454c4e-2605-444d-bff9-b7e8d184091e',\n",
       "   'field_name': 'num_topics_min',\n",
       "   'label': 'num_topics_min (integer)',\n",
       "   'source': 'value:a6454c4e-2605-444d-bff9-b7e8d184091e',\n",
       "   'target': 'module:zdpuAoRTS61Hf3P8nNJFAy1ryxbHQmwjC7K2qpr21X5fRM19t'},\n",
       "  {'id': 'module:zdpuAoRTS61Hf3P8nNJFAy1ryxbHQmwjC7K2qpr21X5fRM19t:tokens_array',\n",
       "   'field_name': 'tokens_array',\n",
       "   'label': 'tokens_array (array)',\n",
       "   'source': 'module:zdpuAqYPUdxbgJK3PxJe7iMDjrDhnNDA2P2ZcpbKc7HNpyPwf',\n",
       "   'target': 'module:zdpuAoRTS61Hf3P8nNJFAy1ryxbHQmwjC7K2qpr21X5fRM19t'},\n",
       "  {'id': 'module:zdpuAqYPUdxbgJK3PxJe7iMDjrDhnNDA2P2ZcpbKc7HNpyPwf:value:c1c95ddb-31a4-472b-bb89-cd070edbb182',\n",
       "   'field_name': 'to_lowercase',\n",
       "   'label': 'to_lowercase (boolean)',\n",
       "   'source': 'value:c1c95ddb-31a4-472b-bb89-cd070edbb182',\n",
       "   'target': 'module:zdpuAqYPUdxbgJK3PxJe7iMDjrDhnNDA2P2ZcpbKc7HNpyPwf'},\n",
       "  {'id': 'module:zdpuAqYPUdxbgJK3PxJe7iMDjrDhnNDA2P2ZcpbKc7HNpyPwf:value:7959e49b-a2b9-4446-84ff-624a1479710a',\n",
       "   'field_name': 'remove_short_tokens',\n",
       "   'label': 'remove_short_tokens (integer)',\n",
       "   'source': 'value:7959e49b-a2b9-4446-84ff-624a1479710a',\n",
       "   'target': 'module:zdpuAqYPUdxbgJK3PxJe7iMDjrDhnNDA2P2ZcpbKc7HNpyPwf'},\n",
       "  {'id': 'module:zdpuAqYPUdxbgJK3PxJe7iMDjrDhnNDA2P2ZcpbKc7HNpyPwf:remove_stopwords',\n",
       "   'field_name': 'remove_stopwords',\n",
       "   'label': 'remove_stopwords (list)',\n",
       "   'source': 'module:zdpuAyow1kztfmcrG3aEeKgk4dgDRNh946qzZxX5uN9z3K4w8',\n",
       "   'target': 'module:zdpuAqYPUdxbgJK3PxJe7iMDjrDhnNDA2P2ZcpbKc7HNpyPwf'},\n",
       "  {'id': 'module:zdpuAyow1kztfmcrG3aEeKgk4dgDRNh946qzZxX5uN9z3K4w8:value:aa5230e0-f7df-451d-b8de-756e30dda42b',\n",
       "   'field_name': 'languages',\n",
       "   'label': 'languages (list)',\n",
       "   'source': 'value:aa5230e0-f7df-451d-b8de-756e30dda42b',\n",
       "   'target': 'module:zdpuAyow1kztfmcrG3aEeKgk4dgDRNh946qzZxX5uN9z3K4w8'},\n",
       "  {'id': 'module:zdpuAyow1kztfmcrG3aEeKgk4dgDRNh946qzZxX5uN9z3K4w8:value:c6b4f1c4-a9c4-4e32-96cc-301e223fc1f9',\n",
       "   'field_name': 'stopword_lists',\n",
       "   'label': 'stopword_lists (list)',\n",
       "   'source': 'value:c6b4f1c4-a9c4-4e32-96cc-301e223fc1f9',\n",
       "   'target': 'module:zdpuAyow1kztfmcrG3aEeKgk4dgDRNh946qzZxX5uN9z3K4w8'},\n",
       "  {'id': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4:value:c6b4f1c4-a9c4-4e32-96cc-301e223fc1f9',\n",
       "   'field_name': 'remove_tokens',\n",
       "   'label': 'remove_tokens (list)',\n",
       "   'source': 'value:c6b4f1c4-a9c4-4e32-96cc-301e223fc1f9',\n",
       "   'target': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4'},\n",
       "  {'id': 'module:zdpuAqYPUdxbgJK3PxJe7iMDjrDhnNDA2P2ZcpbKc7HNpyPwf:tokens_array',\n",
       "   'field_name': 'tokens_array',\n",
       "   'label': 'tokens_array (array)',\n",
       "   'source': 'module:zdpuApN9LQPHc9PKSDp3UmCBdFXYhYMEgPmMbRkhQbKAGWCGa',\n",
       "   'target': 'module:zdpuAqYPUdxbgJK3PxJe7iMDjrDhnNDA2P2ZcpbKc7HNpyPwf'},\n",
       "  {'id': 'module:zdpuApN9LQPHc9PKSDp3UmCBdFXYhYMEgPmMbRkhQbKAGWCGa:texts_array',\n",
       "   'field_name': 'texts_array',\n",
       "   'label': 'texts_array (array)',\n",
       "   'source': 'module:zdpuB1emJxNaL5cYnQ8zEvRaq2azadRPeoQaSqR4eXKE7Up4h',\n",
       "   'target': 'module:zdpuApN9LQPHc9PKSDp3UmCBdFXYhYMEgPmMbRkhQbKAGWCGa'},\n",
       "  {'id': 'module:zdpuB1emJxNaL5cYnQ8zEvRaq2azadRPeoQaSqR4eXKE7Up4h:value:61f3241e-f423-4052-93b2-d50887f6c76b',\n",
       "   'field_name': 'column_name',\n",
       "   'label': 'column_name (string)',\n",
       "   'source': 'value:61f3241e-f423-4052-93b2-d50887f6c76b',\n",
       "   'target': 'module:zdpuB1emJxNaL5cYnQ8zEvRaq2azadRPeoQaSqR4eXKE7Up4h'},\n",
       "  {'id': 'module:zdpuB1emJxNaL5cYnQ8zEvRaq2azadRPeoQaSqR4eXKE7Up4h:table',\n",
       "   'field_name': 'table',\n",
       "   'label': 'table (table)',\n",
       "   'source': 'module:zdpuAzybdPqAwszJEtqjGgiafHHk2y6bVLerT1TfUFkhk94xV',\n",
       "   'target': 'module:zdpuB1emJxNaL5cYnQ8zEvRaq2azadRPeoQaSqR4eXKE7Up4h'},\n",
       "  {'id': 'module:zdpuAzybdPqAwszJEtqjGgiafHHk2y6bVLerT1TfUFkhk94xV:date_array',\n",
       "   'field_name': 'date_array',\n",
       "   'label': 'date_array (array)',\n",
       "   'source': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4',\n",
       "   'target': 'module:zdpuAzybdPqAwszJEtqjGgiafHHk2y6bVLerT1TfUFkhk94xV'},\n",
       "  {'id': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4:array',\n",
       "   'field_name': 'array',\n",
       "   'label': 'array (array)',\n",
       "   'source': 'module:zdpuB19zscMvy4C9ETug9tGkHsTZ3a3N9FHY8htZS1UaPCX3c',\n",
       "   'target': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4'},\n",
       "  {'id': 'module:zdpuB19zscMvy4C9ETug9tGkHsTZ3a3N9FHY8htZS1UaPCX3c:value:0b8ee78f-921f-4479-b2d1-1e760f826875',\n",
       "   'field_name': 'column_name',\n",
       "   'label': 'column_name (string)',\n",
       "   'source': 'value:0b8ee78f-921f-4479-b2d1-1e760f826875',\n",
       "   'target': 'module:zdpuB19zscMvy4C9ETug9tGkHsTZ3a3N9FHY8htZS1UaPCX3c'},\n",
       "  {'id': 'module:zdpuAzybdPqAwszJEtqjGgiafHHk2y6bVLerT1TfUFkhk94xV:source_table',\n",
       "   'field_name': 'source_table',\n",
       "   'label': 'source_table (table)',\n",
       "   'source': 'module:zdpuAkfC7c35pp8SAfCx7Xmk1G1RQMvEymq4mvjDk47e1H9XN',\n",
       "   'target': 'module:zdpuAzybdPqAwszJEtqjGgiafHHk2y6bVLerT1TfUFkhk94xV'},\n",
       "  {'id': 'module:zdpuB19zscMvy4C9ETug9tGkHsTZ3a3N9FHY8htZS1UaPCX3c:table',\n",
       "   'field_name': 'table',\n",
       "   'label': 'table (table)',\n",
       "   'source': 'module:zdpuAkfC7c35pp8SAfCx7Xmk1G1RQMvEymq4mvjDk47e1H9XN',\n",
       "   'target': 'module:zdpuB19zscMvy4C9ETug9tGkHsTZ3a3N9FHY8htZS1UaPCX3c'},\n",
       "  {'id': 'module:zdpuAkfC7c35pp8SAfCx7Xmk1G1RQMvEymq4mvjDk47e1H9XN:text_file_bundle',\n",
       "   'field_name': 'text_file_bundle',\n",
       "   'label': 'text_file_bundle (file_bundle)',\n",
       "   'source': 'module:zdpuAvtJAAff57xASJxvSmQ6w7SRS9W4wPQfUVftGcZAjtQdD',\n",
       "   'target': 'module:zdpuAkfC7c35pp8SAfCx7Xmk1G1RQMvEymq4mvjDk47e1H9XN'},\n",
       "  {'id': 'module:zdpuAvtJAAff57xASJxvSmQ6w7SRS9W4wPQfUVftGcZAjtQdD:value:1d1776f3-239f-4db7-b3dd-7d408bcd0302',\n",
       "   'field_name': 'path',\n",
       "   'label': 'path (string)',\n",
       "   'source': 'value:1d1776f3-239f-4db7-b3dd-7d408bcd0302',\n",
       "   'target': 'module:zdpuAvtJAAff57xASJxvSmQ6w7SRS9W4wPQfUVftGcZAjtQdD'},\n",
       "  {'id': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4:value:9bf6c998-9d8b-4571-ac92-a7e3d8d87892',\n",
       "   'field_name': 'max_index',\n",
       "   'label': 'max_index (integer)',\n",
       "   'source': 'value:9bf6c998-9d8b-4571-ac92-a7e3d8d87892',\n",
       "   'target': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4'},\n",
       "  {'id': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4:value:ebfb1534-cef9-400c-9fdb-59c5d2f6302f',\n",
       "   'field_name': 'min_index',\n",
       "   'label': 'min_index (integer)',\n",
       "   'source': 'value:ebfb1534-cef9-400c-9fdb-59c5d2f6302f',\n",
       "   'target': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4'},\n",
       "  {'id': 'module:zdpuAoRTS61Hf3P8nNJFAy1ryxbHQmwjC7K2qpr21X5fRM19t:value:5704a550-4f4c-44b2-95f3-bf25364a41ee',\n",
       "   'field_name': 'words_per_topic',\n",
       "   'label': 'words_per_topic (integer)',\n",
       "   'source': 'value:5704a550-4f4c-44b2-95f3-bf25364a41ee',\n",
       "   'target': 'module:zdpuAoRTS61Hf3P8nNJFAy1ryxbHQmwjC7K2qpr21X5fRM19t'}]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = graph.nodes.data()\n",
    "augmented_nodes = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, node in enumerate(nodes):\n",
    "    node_dict = {\n",
    "        \"id\": node[0],\n",
    "        \"desc\": node[1],\n",
    "        \"parentIds\": [pred for pred in graph.predecessors(node[0])],\n",
    "        \"info\": get_info(node)\n",
    "    }\n",
    "    augmented_nodes[idx] = node_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'id': 'value:fe802251-d595-4f09-869a-71e67eca18f1',\n",
       "  'desc': {'data_type': 'dict',\n",
       "   'label': '[this value]',\n",
       "   'node_type': 'value',\n",
       "   'data_type_config': {},\n",
       "   'level': 1},\n",
       "  'parentIds': ['module:zdpuAoRTS61Hf3P8nNJFAy1ryxbHQmwjC7K2qpr21X5fRM19t'],\n",
       "  'info': {'preview': \"dict_data={'7': 0.2352272347011528, '8': 0.22535913106326597, '9': 0.22648812236315757} data_schema={'title': 'dict', 'type': 'object'} python_class=PythonClass(model_id=dict, category=instance.wrapped_python_class, fields=[python_class_name, python_module_name, full_name])\"}},\n",
       " 1: {'id': 'module:zdpuAoRTS61Hf3P8nNJFAy1ryxbHQmwjC7K2qpr21X5fRM19t',\n",
       "  'desc': {'module_type': 'generate.LDA.for.tokens_array',\n",
       "   'module_config': {'constants': {}, 'defaults': {}},\n",
       "   'label': 'generate.LDA.for.tokens_array',\n",
       "   'node_type': 'operation',\n",
       "   'level': 3},\n",
       "  'parentIds': ['value:195805cd-bdda-45d5-abb3-968fc5d3bfd5',\n",
       "   'value:d68fb5ef-1c43-4aef-8957-3f7f1f7e6de0',\n",
       "   'value:a6454c4e-2605-444d-bff9-b7e8d184091e',\n",
       "   'module:zdpuAqYPUdxbgJK3PxJe7iMDjrDhnNDA2P2ZcpbKc7HNpyPwf',\n",
       "   'value:5704a550-4f4c-44b2-95f3-bf25364a41ee'],\n",
       "  'info': {'type_name': 'generate.LDA.for.tokens_array',\n",
       "   'documentation': {'description': 'Perform Latent Dirichlet Allocation on a tokenized corpus.',\n",
       "    'doc': 'This module computes models for a range of number of topics provided by the user.'},\n",
       "   'authors': {'authors': [{'name': 'Markus Binsteiner',\n",
       "      'email': 'markus@frkl.io'}]},\n",
       "   'context': {'references': {'source_repo': {'url': AnyUrl('https://github.com/DHARPA-Project/kiara_plugin.language_processing', scheme='https', host='github.com', tld='com', host_type='domain', path='/DHARPA-Project/kiara_plugin.language_processing'),\n",
       "      'desc': 'The module package git repository.'},\n",
       "     'documentation': {'url': AnyUrl('https://DHARPA-Project.github.io/kiara_plugin.language_processing/', scheme='https', host='DHARPA-Project.github.io', tld='io', host_type='domain', path='/kiara_plugin.language_processing/'),\n",
       "      'desc': 'The url for the module package documentation.'}},\n",
       "    'tags': ['language_processing', 'LDA', 'tokens'],\n",
       "    'labels': {'package': 'kiara_plugin.language_processing'}},\n",
       "   'python_class': {'python_class_name': 'LDAModule',\n",
       "    'python_module_name': 'kiara_plugin.language_processing.modules.lda',\n",
       "    'full_name': 'kiara_plugin.language_processing.modules.lda.LDAModule'},\n",
       "   'process_src': 'def process(self, inputs: ValueMap, outputs: ValueMap) -> None:\\n\\n    from gensim import corpora\\n\\n    logging.getLogger(\"gensim\").setLevel(logging.ERROR)\\n    tokens_array: KiaraArray = inputs.get_value_data(\"tokens_array\")\\n    tokens = tokens_array.arrow_array.to_pylist()\\n\\n    words_per_topic = inputs.get_value_data(\"words_per_topic\")\\n\\n    num_topics_min = inputs.get_value_data(\"num_topics_min\")\\n    num_topics_max = inputs.get_value_data(\"num_topics_max\")\\n    if num_topics_max is None:\\n        num_topics_max = num_topics_min\\n\\n    compute_coherence = inputs.get_value_data(\"compute_coherence\")\\n    id2word = corpora.Dictionary(tokens)\\n    corpus = [id2word.doc2bow(text) for text in tokens]\\n\\n    # model = gensim.models.ldamulticore.LdaMulticore(\\n    #     corpus, id2word=id2word, num_topics=num_topics, eval_every=None\\n    # )\\n\\n    models = {}\\n    model_tables = {}\\n    coherence = {}\\n\\n    # multi_threaded = False\\n    # if not multi_threaded:\\n\\n    for nt in range(num_topics_min, num_topics_max + 1):\\n        model = self.create_model(corpus=corpus, num_topics=nt, id2word=id2word)\\n        models[nt] = model\\n        topic_print_model = model.print_topics(num_words=words_per_topic)\\n        # dbg(topic_print_model)\\n        # df = pd.DataFrame(topic_print_model, columns=[\"topic_id\", \"words\"])\\n        # TODO: create table directly\\n        # result_table = Table.from_pandas(df)\\n        model_tables[nt] = topic_print_model\\n\\n        if compute_coherence:\\n            coherence_result = self.compute_coherence(\\n                model=model, corpus_model=tokens, id2word=id2word\\n            )\\n            coherence[nt] = coherence_result\\n\\n    # else:\\n    #     def create_model(num_topics):\\n    #         model = self.create_model(corpus=corpus, num_topics=num_topics, id2word=id2word)\\n    #         topic_print_model = model.print_topics(num_words=30)\\n    #         df = pd.DataFrame(topic_print_model, columns=[\"topic_id\", \"words\"])\\n    #         # TODO: create table directly\\n    #         result_table = Table.from_pandas(df)\\n    #         coherence_result = None\\n    #         if compute_coherence:\\n    #             coherence_result = self.compute_coherence(model=model, corpus_model=tokens, id2word=id2word)\\n    #         return (num_topics, model, result_table, coherence_result)\\n    #\\n    #     executor = ThreadPoolExecutor()\\n    #     results: typing.Any = executor.map(create_model, range(num_topics_min, num_topics_max+1))\\n    #     executor.shutdown(wait=True)\\n    #     for r in results:\\n    #         models[r[0]] = r[1]\\n    #         model_tables[r[0]] = r[2]\\n    #         if compute_coherence:\\n    #             coherence[r[0]] = r[3]\\n\\n    # df_coherence = pd.DataFrame(coherence.keys(), columns=[\"Number of topics\"])\\n    # df_coherence[\"Coherence\"] = coherence.values()\\n\\n    if compute_coherence:\\n        coherence_table = self.assemble_coherence(\\n            models_dict=models, words_per_topic=words_per_topic\\n        )\\n    else:\\n        coherence_table = None\\n\\n    coherence_map = {k: v.item() for k, v in coherence.items()}\\n\\n    outputs.set_values(\\n        topic_models=model_tables,\\n        coherence_table=coherence_table,\\n        coherence_map=coherence_map,\\n    )\\n',\n",
       "   'config': {'python_class': {'python_class_name': 'KiaraModuleConfig',\n",
       "     'python_module_name': 'kiara.models.module',\n",
       "     'full_name': 'kiara.models.module.KiaraModuleConfig'},\n",
       "    'config_values': {'constants': {'description': 'Value constants for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'defaults': {'description': 'Value defaults for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False}}}}},\n",
       " 2: {'id': 'value:195805cd-bdda-45d5-abb3-968fc5d3bfd5',\n",
       "  'desc': {'label': 'tokenize_by_word (boolean)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'boolean',\n",
       "   'data_type_config': {},\n",
       "   'level': 8},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': 'True'}},\n",
       " 3: {'id': 'value:d68fb5ef-1c43-4aef-8957-3f7f1f7e6de0',\n",
       "  'desc': {'label': 'num_topics_max (integer)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'integer',\n",
       "   'data_type_config': {},\n",
       "   'level': 4},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': '9'}},\n",
       " 4: {'id': 'value:a6454c4e-2605-444d-bff9-b7e8d184091e',\n",
       "  'desc': {'label': 'num_topics_min (integer)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'integer',\n",
       "   'data_type_config': {},\n",
       "   'level': 4},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': '7'}},\n",
       " 5: {'id': 'module:zdpuAqYPUdxbgJK3PxJe7iMDjrDhnNDA2P2ZcpbKc7HNpyPwf',\n",
       "  'desc': {'module_type': 'preprocess.tokens_array',\n",
       "   'module_config': {'constants': {}, 'defaults': {}},\n",
       "   'label': 'preprocess.tokens_array',\n",
       "   'node_type': 'operation',\n",
       "   'level': 5},\n",
       "  'parentIds': ['value:c1c95ddb-31a4-472b-bb89-cd070edbb182',\n",
       "   'value:7959e49b-a2b9-4446-84ff-624a1479710a',\n",
       "   'module:zdpuAyow1kztfmcrG3aEeKgk4dgDRNh946qzZxX5uN9z3K4w8',\n",
       "   'module:zdpuApN9LQPHc9PKSDp3UmCBdFXYhYMEgPmMbRkhQbKAGWCGa'],\n",
       "  'info': {'type_name': 'preprocess.tokens_array',\n",
       "   'documentation': {'description': 'Preprocess lists of tokens, incl. lowercasing, remove special characers, etc.',\n",
       "    'doc': \"Lowercasing: Lowercase the words. This operation is a double-edged sword. It can be effective at yielding potentially better results in the case of relatively small datasets or datatsets with a high percentage of OCR mistakes. For instance, if lowercasing is not performed, the algorithm will treat USA, Usa, usa, UsA, uSA, etc. as distinct tokens, even though they may all refer to the same entity. On the other hand, if the dataset does not contain such OCR mistakes, then it may become difficult to distinguish between homonyms and make interpreting the topics much harder.\\n\\nRemoving stopwords and words with less than three characters: Remove low information words. These are typically words such as articles, pronouns, prepositions, conjunctions, etc. which are not semantically salient. There are numerous stopword lists available for many, though not all, languages which can be easily adapted to the individual researcher's needs. Removing words with less than three characters may additionally remove many OCR mistakes. Both these operations have the dual advantage of yielding more reliable results while reducing the size of the dataset, thus in turn reducing the required processing power. This step can therefore hardly be considered optional in TM.\\n\\nNoise removal: Remove elements such as punctuation marks, special characters, numbers, html formatting, etc. This operation is again concerned with removing elements that may not be relevant to the text analysis and in fact interfere with it. Depending on the dataset and research question, this operation can become essential.\"},\n",
       "   'authors': {'authors': [{'name': 'Markus Binsteiner',\n",
       "      'email': 'markus@frkl.io'}]},\n",
       "   'context': {'references': {'source_repo': {'url': AnyUrl('https://github.com/DHARPA-Project/kiara_plugin.language_processing', scheme='https', host='github.com', tld='com', host_type='domain', path='/DHARPA-Project/kiara_plugin.language_processing'),\n",
       "      'desc': 'The module package git repository.'},\n",
       "     'documentation': {'url': AnyUrl('https://DHARPA-Project.github.io/kiara_plugin.language_processing/', scheme='https', host='DHARPA-Project.github.io', tld='io', host_type='domain', path='/kiara_plugin.language_processing/'),\n",
       "      'desc': 'The url for the module package documentation.'}},\n",
       "    'tags': ['language_processing', 'tokens', 'preprocess'],\n",
       "    'labels': {'package': 'kiara_plugin.language_processing'}},\n",
       "   'python_class': {'python_class_name': 'PreprocessModule',\n",
       "    'python_module_name': 'kiara_plugin.language_processing.modules.tokens',\n",
       "    'full_name': 'kiara_plugin.language_processing.modules.tokens.PreprocessModule'},\n",
       "   'process_src': 'def process(self, inputs: ValueMap, outputs: ValueMap):\\n\\n    import polars as pl\\n    import pyarrow as pa\\n\\n    tokens_array: KiaraArray = inputs.get_value_data(\"tokens_array\")\\n    lowercase: bool = inputs.get_value_data(\"to_lowercase\")\\n    remove_alphanumeric: bool = inputs.get_value_data(\"remove_alphanumeric\")\\n    remove_non_alpha: bool = inputs.get_value_data(\"remove_non_alpha\")\\n    remove_all_numeric: bool = inputs.get_value_data(\"remove_all_numeric\")\\n    remove_short_tokens: int = inputs.get_value_data(\"remove_short_tokens\")\\n\\n    if remove_short_tokens is None:\\n        remove_short_tokens = -1\\n\\n    _remove_stopwords = inputs.get_value_obj(\"remove_stopwords\")\\n    if _remove_stopwords.is_set:\\n        stopword_list: Optional[Iterable[str]] = _remove_stopwords.data.list_data\\n    else:\\n        stopword_list = None\\n\\n    # it\\'s better to have one method every token goes through, then do every test seperately for the token list\\n    # because that way each token only needs to be touched once (which is more effective)\\n    def check_token(token: str) -> Optional[str]:\\n\\n        # remove short tokens first, since we can save ourselves all the other checks (which are more expensive)\\n        if remove_short_tokens > 0:\\n            if len(token) <= remove_short_tokens:\\n                return None\\n\\n        _token: str = token\\n        if lowercase:\\n            _token = _token.lower()\\n\\n        if remove_non_alpha:\\n            match = _token if _token.isalpha() else None\\n            if match is None:\\n                return None\\n\\n        # if remove_non_alpha was set, we don\\'t need to worry about tokens that include numbers, since they are already filtered out\\n        if remove_alphanumeric and not remove_non_alpha:\\n            match = _token if _token.isalnum() else None\\n            if match is None:\\n                return None\\n\\n        # all-number tokens are already filtered out if the remove_non_alpha methods above ran\\n        if remove_all_numeric and not remove_non_alpha:\\n            match = None if _token.isdigit() else _token\\n            if match is None:\\n                return None\\n\\n        if stopword_list and _token and _token.lower() in stopword_list:\\n            return None\\n\\n        return _token\\n\\n    series = pl.Series(name=\"tokens\", values=tokens_array.arrow_array)\\n    result = series.apply(\\n        lambda token_list: [\\n            x for x in (check_token(token) for token in token_list) if x is not None\\n        ]\\n    )\\n    result_array = result.to_arrow()\\n\\n    # TODO: remove this cast once the array data type can handle non-chunked arrays\\n    chunked = pa.chunked_array(result_array)\\n    outputs.set_values(tokens_array=chunked)\\n',\n",
       "   'config': {'python_class': {'python_class_name': 'KiaraModuleConfig',\n",
       "     'python_module_name': 'kiara.models.module',\n",
       "     'full_name': 'kiara.models.module.KiaraModuleConfig'},\n",
       "    'config_values': {'constants': {'description': 'Value constants for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'defaults': {'description': 'Value defaults for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False}}}}},\n",
       " 6: {'id': 'value:c1c95ddb-31a4-472b-bb89-cd070edbb182',\n",
       "  'desc': {'label': 'to_lowercase (boolean)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'boolean',\n",
       "   'data_type_config': {},\n",
       "   'level': 6},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': 'False'}},\n",
       " 7: {'id': 'value:7959e49b-a2b9-4446-84ff-624a1479710a',\n",
       "  'desc': {'label': 'remove_short_tokens (integer)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'integer',\n",
       "   'data_type_config': {},\n",
       "   'level': 6},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': '0'}},\n",
       " 8: {'id': 'module:zdpuAyow1kztfmcrG3aEeKgk4dgDRNh946qzZxX5uN9z3K4w8',\n",
       "  'desc': {'module_type': 'create.stopwords_list',\n",
       "   'module_config': {'constants': {}, 'defaults': {}},\n",
       "   'label': 'create.stopwords_list',\n",
       "   'node_type': 'operation',\n",
       "   'level': 7},\n",
       "  'parentIds': ['value:aa5230e0-f7df-451d-b8de-756e30dda42b',\n",
       "   'value:c6b4f1c4-a9c4-4e32-96cc-301e223fc1f9'],\n",
       "  'info': {'type_name': 'create.stopwords_list',\n",
       "   'documentation': {'description': 'Create a list of stopwords from one or multiple sources.',\n",
       "    'doc': 'This will download nltk stopwords if necessary, and merge all input lists into a single, sorted list without duplicates.'},\n",
       "   'authors': {'authors': [{'name': 'Markus Binsteiner',\n",
       "      'email': 'markus@frkl.io'}]},\n",
       "   'context': {'references': {'source_repo': {'url': AnyUrl('https://github.com/DHARPA-Project/kiara_plugin.language_processing', scheme='https', host='github.com', tld='com', host_type='domain', path='/DHARPA-Project/kiara_plugin.language_processing'),\n",
       "      'desc': 'The module package git repository.'},\n",
       "     'documentation': {'url': AnyUrl('https://DHARPA-Project.github.io/kiara_plugin.language_processing/', scheme='https', host='DHARPA-Project.github.io', tld='io', host_type='domain', path='/kiara_plugin.language_processing/'),\n",
       "      'desc': 'The url for the module package documentation.'}},\n",
       "    'tags': ['language_processing'],\n",
       "    'labels': {'package': 'kiara_plugin.language_processing'}},\n",
       "   'python_class': {'python_class_name': 'AssembleStopwordsModule',\n",
       "    'python_module_name': 'kiara_plugin.language_processing.modules.tokens',\n",
       "    'full_name': 'kiara_plugin.language_processing.modules.tokens.AssembleStopwordsModule'},\n",
       "   'process_src': 'def process(self, inputs: ValueMap, outputs: ValueMap):\\n\\n    stopwords = set()\\n    _languages = inputs.get_value_obj(\"languages\")\\n\\n    if _languages.is_set:\\n        all_stopwords = get_stopwords()\\n        languages: ListModel = _languages.data\\n\\n        for language in languages.list_data:\\n\\n            if language not in all_stopwords.fileids():\\n                raise KiaraProcessingException(\\n                    f\"Invalid language: {language}. Available: {\\', \\'.join(all_stopwords.fileids())}.\"\\n                )\\n            stopwords.update(get_stopwords().words(language))\\n\\n    _stopword_lists = inputs.get_value_obj(\"stopword_lists\")\\n    if _stopword_lists.is_set:\\n        stopword_lists: ListModel = _stopword_lists.data\\n        for stopword_list in stopword_lists.list_data:\\n            if isinstance(stopword_list, str):\\n                stopwords.add(stopword_list)\\n            else:\\n                stopwords.update(stopword_list)\\n\\n    outputs.set_value(\"stopwords_list\", sorted(stopwords))\\n',\n",
       "   'config': {'python_class': {'python_class_name': 'KiaraModuleConfig',\n",
       "     'python_module_name': 'kiara.models.module',\n",
       "     'full_name': 'kiara.models.module.KiaraModuleConfig'},\n",
       "    'config_values': {'constants': {'description': 'Value constants for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'defaults': {'description': 'Value defaults for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False}}}}},\n",
       " 9: {'id': 'value:aa5230e0-f7df-451d-b8de-756e30dda42b',\n",
       "  'desc': {'label': 'languages (list)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'list',\n",
       "   'data_type_config': {},\n",
       "   'level': 8},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': \"list_data=['italian'] item_schema={'title': 'list', 'type': 'object'} python_class=PythonClass(model_id=list, category=instance.wrapped_python_class, fields=[python_class_name, python_module_name, full_name])\"}},\n",
       " 10: {'id': 'value:c6b4f1c4-a9c4-4e32-96cc-301e223fc1f9',\n",
       "  'desc': {'label': 'remove_tokens (list)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'list',\n",
       "   'data_type_config': {},\n",
       "   'level': 14},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': \"list_data=[] item_schema={'title': 'list', 'type': 'object'} python_class=PythonClass(model_id=list, category=instance.wrapped_python_class, fields=[python_class_name, python_module_name, full_name])\"}},\n",
       " 11: {'id': 'module:zdpuApN9LQPHc9PKSDp3UmCBdFXYhYMEgPmMbRkhQbKAGWCGa',\n",
       "  'desc': {'module_type': 'tokenize.texts_array',\n",
       "   'module_config': {'constants': {}, 'defaults': {}},\n",
       "   'label': 'tokenize.texts_array',\n",
       "   'node_type': 'operation',\n",
       "   'level': 7},\n",
       "  'parentIds': ['module:zdpuB1emJxNaL5cYnQ8zEvRaq2azadRPeoQaSqR4eXKE7Up4h',\n",
       "   'value:195805cd-bdda-45d5-abb3-968fc5d3bfd5'],\n",
       "  'info': {'type_name': 'tokenize.texts_array',\n",
       "   'documentation': {'description': 'Split sentences into words or words into characters.',\n",
       "    'doc': 'In other words, this operation establishes the word boundaries (i.e., tokens) a very helpful way of finding patterns. It is also the typical step prior to stemming and lemmatization'},\n",
       "   'authors': {'authors': [{'name': 'Markus Binsteiner',\n",
       "      'email': 'markus@frkl.io'}]},\n",
       "   'context': {'references': {'source_repo': {'url': AnyUrl('https://github.com/DHARPA-Project/kiara_plugin.language_processing', scheme='https', host='github.com', tld='com', host_type='domain', path='/DHARPA-Project/kiara_plugin.language_processing'),\n",
       "      'desc': 'The module package git repository.'},\n",
       "     'documentation': {'url': AnyUrl('https://DHARPA-Project.github.io/kiara_plugin.language_processing/', scheme='https', host='DHARPA-Project.github.io', tld='io', host_type='domain', path='/kiara_plugin.language_processing/'),\n",
       "      'desc': 'The url for the module package documentation.'}},\n",
       "    'tags': ['language_processing', 'tokenize', 'tokens'],\n",
       "    'labels': {'package': 'kiara_plugin.language_processing'}},\n",
       "   'python_class': {'python_class_name': 'TokenizeTextArrayeModule',\n",
       "    'python_module_name': 'kiara_plugin.language_processing.modules.tokens',\n",
       "    'full_name': 'kiara_plugin.language_processing.modules.tokens.TokenizeTextArrayeModule'},\n",
       "   'process_src': 'def process(self, inputs: ValueMap, outputs: ValueMap):\\n\\n    pass\\n\\n    import nltk\\n    import polars as pl\\n    import pyarrow as pa\\n\\n    array: KiaraArray = inputs.get_value_data(\"texts_array\")\\n    # tokenize_by_word: bool = inputs.get_value_data(\"tokenize_by_word\")\\n\\n    column: pa.ChunkedArray = array.arrow_array\\n\\n    # warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\\n\\n    def word_tokenize(word):\\n        result = nltk.word_tokenize(word)\\n        return result\\n\\n    series = pl.Series(name=\"tokens\", values=column)\\n    result = series.apply(word_tokenize)\\n\\n    result_array = result.to_arrow()\\n\\n    # TODO: remove this cast once the array data type can handle non-chunked arrays\\n    chunked = pa.chunked_array(result_array)\\n    outputs.set_values(tokens_array=chunked)\\n',\n",
       "   'config': {'python_class': {'python_class_name': 'KiaraModuleConfig',\n",
       "     'python_module_name': 'kiara.models.module',\n",
       "     'full_name': 'kiara.models.module.KiaraModuleConfig'},\n",
       "    'config_values': {'constants': {'description': 'Value constants for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'defaults': {'description': 'Value defaults for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False}}}}},\n",
       " 12: {'id': 'module:zdpuB1emJxNaL5cYnQ8zEvRaq2azadRPeoQaSqR4eXKE7Up4h',\n",
       "  'desc': {'module_type': 'table.cut_column',\n",
       "   'module_config': {'constants': {'column_name': 'content'}, 'defaults': {}},\n",
       "   'label': 'table.cut_column',\n",
       "   'node_type': 'operation',\n",
       "   'level': 9},\n",
       "  'parentIds': ['value:61f3241e-f423-4052-93b2-d50887f6c76b',\n",
       "   'module:zdpuAzybdPqAwszJEtqjGgiafHHk2y6bVLerT1TfUFkhk94xV'],\n",
       "  'info': {'type_name': 'table.cut_column',\n",
       "   'documentation': {'description': 'Cut off one column from a table, returning an array.',\n",
       "    'doc': None},\n",
       "   'authors': {'authors': [{'name': 'Markus Binsteiner',\n",
       "      'email': 'markus@frkl.io'}]},\n",
       "   'context': {'references': {'source_repo': {'url': AnyUrl('https://github.com/DHARPA-Project/kiara_plugin.tabular', scheme='https', host='github.com', tld='com', host_type='domain', path='/DHARPA-Project/kiara_plugin.tabular'),\n",
       "      'desc': 'The module package git repository.'},\n",
       "     'documentation': {'url': AnyUrl('https://DHARPA-Project.github.io/kiara_plugin.tabular/', scheme='https', host='DHARPA-Project.github.io', tld='io', host_type='domain', path='/kiara_plugin.tabular/'),\n",
       "      'desc': 'The url for the module package documentation.'}},\n",
       "    'tags': ['tabular'],\n",
       "    'labels': {'package': 'kiara_plugin.tabular'}},\n",
       "   'python_class': {'python_class_name': 'CutColumnModule',\n",
       "    'python_module_name': 'kiara_plugin.tabular.modules.table',\n",
       "    'full_name': 'kiara_plugin.tabular.modules.table.CutColumnModule'},\n",
       "   'process_src': 'def process(self, inputs: ValueMap, outputs: ValueMap) -> None:\\n\\n    import pyarrow as pa\\n\\n    column_name: str = inputs.get_value_data(\"column_name\")\\n\\n    table_value: Value = inputs.get_value_obj(\"table\")\\n    table_metadata: KiaraTableMetadata = table_value.get_property_data(\\n        \"metadata.table\"\\n    )\\n\\n    available = table_metadata.table.column_names\\n\\n    if column_name not in available:\\n        raise KiaraProcessingException(\\n            f\"Invalid column name \\'{column_name}\\'. Available column names: {\\', \\'.join(available)}\"\\n        )\\n\\n    table: pa.Table = table_value.data.arrow_table\\n    column = table.column(column_name)\\n\\n    outputs.set_value(\"array\", column)\\n',\n",
       "   'config': {'python_class': {'python_class_name': 'KiaraModuleConfig',\n",
       "     'python_module_name': 'kiara.models.module',\n",
       "     'full_name': 'kiara.models.module.KiaraModuleConfig'},\n",
       "    'config_values': {'constants': {'description': 'Value constants for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'defaults': {'description': 'Value defaults for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False}}}}},\n",
       " 13: {'id': 'value:61f3241e-f423-4052-93b2-d50887f6c76b',\n",
       "  'desc': {'label': 'column_name (string)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'string',\n",
       "   'data_type_config': {},\n",
       "   'level': 10},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': 'content'}},\n",
       " 14: {'id': 'module:zdpuAzybdPqAwszJEtqjGgiafHHk2y6bVLerT1TfUFkhk94xV',\n",
       "  'desc': {'module_type': 'table.merge',\n",
       "   'module_config': {'constants': {},\n",
       "    'defaults': {},\n",
       "    'inputs_schema': {'source_table': {'type': 'table',\n",
       "      'type_config': {},\n",
       "      'default': '__not_set__',\n",
       "      'optional': False,\n",
       "      'is_constant': False,\n",
       "      'doc': {'description': 'The original table.', 'doc': None}},\n",
       "     'date_array': {'type': 'array',\n",
       "      'type_config': {},\n",
       "      'default': '__not_set__',\n",
       "      'optional': False,\n",
       "      'is_constant': False,\n",
       "      'doc': {'description': 'The array containing the parsed date items.',\n",
       "       'doc': None}}},\n",
       "    'column_map': {'date': 'date_array',\n",
       "     'content': 'source_table.content',\n",
       "     'file_name': 'source_table.file_name'}},\n",
       "   'label': 'table.merge',\n",
       "   'node_type': 'operation',\n",
       "   'level': 11},\n",
       "  'parentIds': ['module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4',\n",
       "   'module:zdpuAkfC7c35pp8SAfCx7Xmk1G1RQMvEymq4mvjDk47e1H9XN'],\n",
       "  'info': {'type_name': 'table.merge',\n",
       "   'documentation': {'description': 'Create a table from other tables and/or arrays.',\n",
       "    'doc': \"This module needs configuration to be set (for now). It's currently not possible to merge an arbitrary\\nnumber of tables/arrays, all tables to be merged must be specified in the module configuration.\\n\\nColumn names of the resulting table can be controlled by the 'column_map' configuration, which takes the\\ndesired column name as key, and a field-name in the following format as value:\\n- '[inputs_schema key]' for inputs of type 'array'\\n- '[inputs_schema_key].orig_column_name' for inputs of type 'table'\"},\n",
       "   'authors': {'authors': [{'name': 'Markus Binsteiner',\n",
       "      'email': 'markus@frkl.io'}]},\n",
       "   'context': {'references': {'source_repo': {'url': AnyUrl('https://github.com/DHARPA-Project/kiara_plugin.tabular', scheme='https', host='github.com', tld='com', host_type='domain', path='/DHARPA-Project/kiara_plugin.tabular'),\n",
       "      'desc': 'The module package git repository.'},\n",
       "     'documentation': {'url': AnyUrl('https://DHARPA-Project.github.io/kiara_plugin.tabular/', scheme='https', host='DHARPA-Project.github.io', tld='io', host_type='domain', path='/kiara_plugin.tabular/'),\n",
       "      'desc': 'The url for the module package documentation.'}},\n",
       "    'tags': ['tabular'],\n",
       "    'labels': {'package': 'kiara_plugin.tabular'}},\n",
       "   'python_class': {'python_class_name': 'MergeTableModule',\n",
       "    'python_module_name': 'kiara_plugin.tabular.modules.table',\n",
       "    'full_name': 'kiara_plugin.tabular.modules.table.MergeTableModule'},\n",
       "   'process_src': 'def process(self, inputs: ValueMap, outputs: ValueMap, job_log: JobLog) -> None:\\n\\n    import pyarrow as pa\\n\\n    inputs_schema: Dict[str, Any] = self.get_config_value(\"inputs_schema\")\\n    column_map: Dict[str, str] = self.get_config_value(\"column_map\")\\n\\n    sources = {}\\n    for field_name in inputs_schema.keys():\\n        sources[field_name] = inputs.get_value_data(field_name)\\n\\n    len_dict = {}\\n    arrays = {}\\n\\n    column_map_final = dict(column_map)\\n\\n    for source_key, table_or_array in sources.items():\\n\\n        if isinstance(table_or_array, KiaraTable):\\n            rows = table_or_array.num_rows\\n            for name in table_or_array.column_names:\\n                array_name = f\"{source_key}.{name}\"\\n                if column_map and array_name not in column_map.values():\\n                    job_log.add_log(\\n                        f\"Ignoring column \\'{name}\\' of input table \\'{source_key}\\': not listed in column_map.\"\\n                    )\\n                    continue\\n\\n                column = table_or_array.arrow_table.column(name)\\n                arrays[array_name] = column\\n                if not column_map:\\n                    if name in column_map_final:\\n                        raise Exception(\\n                            f\"Can\\'t merge table, duplicate column name: {name}.\"\\n                        )\\n                    column_map_final[name] = array_name\\n\\n        elif isinstance(table_or_array, KiaraArray):\\n\\n            if column_map and source_key not in column_map.values():\\n                job_log.add_log(\\n                    f\"Ignoring array \\'{source_key}\\': not listed in column_map.\"\\n                )\\n                continue\\n\\n            rows = len(table_or_array)\\n            arrays[source_key] = table_or_array.arrow_array\\n\\n            if not column_map:\\n                if source_key in column_map_final.keys():\\n                    raise Exception(\\n                        f\"Can\\'t merge table, duplicate column name: {source_key}.\"\\n                    )\\n                column_map_final[source_key] = source_key\\n\\n        else:\\n            raise KiaraProcessingException(\\n                f\"Can\\'t merge table: invalid type \\'{type(table_or_array)}\\' for source \\'{source_key}\\'.\"\\n            )\\n\\n        len_dict[source_key] = rows\\n\\n    all_rows = None\\n    for source_key, rows in len_dict.items():\\n        if all_rows is None:\\n            all_rows = rows\\n        else:\\n            if all_rows != rows:\\n                all_rows = None\\n                break\\n\\n    if all_rows is None:\\n        len_str = \"\"\\n        for name, rows in len_dict.items():\\n            len_str = f\" {name} ({rows})\"\\n\\n        raise KiaraProcessingException(\\n            f\"Can\\'t merge table, sources have different lengths: {len_str}\"\\n        )\\n\\n    column_names = []\\n    columns = []\\n    for column_name, ref in column_map_final.items():\\n        column_names.append(column_name)\\n        column = arrays[ref]\\n        columns.append(column)\\n\\n    table = pa.Table.from_arrays(arrays=columns, names=column_names)\\n\\n    outputs.set_value(\"table\", table)\\n',\n",
       "   'config': {'python_class': {'python_class_name': 'MergeTableConfig',\n",
       "     'python_module_name': 'kiara_plugin.tabular.modules.table',\n",
       "     'full_name': 'kiara_plugin.tabular.modules.table.MergeTableConfig'},\n",
       "    'config_values': {'constants': {'description': 'Value constants for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'defaults': {'description': 'Value defaults for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'inputs_schema': {'description': 'A dict describing the inputs for this merge process.',\n",
       "      'type': 'object',\n",
       "      'value_default': None,\n",
       "      'required': True},\n",
       "     'column_map': {'description': 'A map describing',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False}}}}},\n",
       " 15: {'id': 'module:zdpuAsncFffKfH2J6qok1LLfBWGF3BTHXHVyYK4vV86tujCP4',\n",
       "  'desc': {'module_type': 'parse.date_array',\n",
       "   'module_config': {'constants': {},\n",
       "    'defaults': {},\n",
       "    'add_inputs': True,\n",
       "    'input_fields': [],\n",
       "    'force_non_null': True,\n",
       "    'min_index': None,\n",
       "    'max_index': None,\n",
       "    'remove_tokens': []},\n",
       "   'label': 'parse.date_array',\n",
       "   'node_type': 'operation',\n",
       "   'level': 13},\n",
       "  'parentIds': ['module:zdpuB19zscMvy4C9ETug9tGkHsTZ3a3N9FHY8htZS1UaPCX3c',\n",
       "   'value:195805cd-bdda-45d5-abb3-968fc5d3bfd5',\n",
       "   'value:9bf6c998-9d8b-4571-ac92-a7e3d8d87892',\n",
       "   'value:ebfb1534-cef9-400c-9fdb-59c5d2f6302f',\n",
       "   'value:c6b4f1c4-a9c4-4e32-96cc-301e223fc1f9'],\n",
       "  'info': {'type_name': 'parse.date_array',\n",
       "   'documentation': {'description': 'Create an array of date objects from an array of strings.',\n",
       "    'doc': \"This module is very simplistic at the moment, more functionality and options will be added in the future.\\n\\nAt its core, this module uses the standard parser from the\\n[dateutil](https://github.com/dateutil/dateutil) package to parse strings into dates. As this parser can't handle\\n complex strings, the input strings can be pre-processed in the following ways:\\n\\n- 'cut' non-relevant parts of the string (using 'min_index' & 'max_index' input/config options)\\n- remove matching tokens from the string, and replace them with a single whitespace (using the 'remove_tokens' option)\\n\\nBy default, if an input string can't be parsed this module will raise an exception. This can be prevented by\\nsetting this modules 'force_non_null' config option or input to 'False', in which case un-parsable strings\\nwill appear as 'NULL' value in the resulting array.\"},\n",
       "   'authors': {'authors': [{'name': 'Markus Binsteiner',\n",
       "      'email': 'markus@frkl.io'}]},\n",
       "   'context': {'references': {'source_repo': {'url': AnyUrl('https://github.com/DHARPA-Project/kiara_plugin.tabular', scheme='https', host='github.com', tld='com', host_type='domain', path='/DHARPA-Project/kiara_plugin.tabular'),\n",
       "      'desc': 'The module package git repository.'},\n",
       "     'documentation': {'url': AnyUrl('https://DHARPA-Project.github.io/kiara_plugin.tabular/', scheme='https', host='DHARPA-Project.github.io', tld='io', host_type='domain', path='/kiara_plugin.tabular/'),\n",
       "      'desc': 'The url for the module package documentation.'}},\n",
       "    'tags': ['tabular'],\n",
       "    'labels': {'package': 'kiara_plugin.tabular'}},\n",
       "   'python_class': {'python_class_name': 'ExtractDateModule',\n",
       "    'python_module_name': 'kiara_plugin.tabular.modules.array',\n",
       "    'full_name': 'kiara_plugin.tabular.modules.array.ExtractDateModule'},\n",
       "   'process_src': 'def process(self, inputs: ValueMap, outputs: ValueMap, job_log: JobLog):\\n\\n    import polars as pl\\n    import pyarrow as pa\\n    from dateutil import parser\\n\\n    force_non_null: bool = self.get_data_for_field(\\n        field_name=\"force_non_null\", inputs=inputs\\n    )\\n    min_pos: Union[None, int] = self.get_data_for_field(\\n        field_name=\"min_index\", inputs=inputs\\n    )\\n    if min_pos is None:\\n        min_pos = 0\\n    max_pos: Union[None, int] = self.get_data_for_field(\\n        field_name=\"max_index\", inputs=inputs\\n    )\\n    remove_tokens: Iterable[str] = self.get_data_for_field(\\n        field_name=\"remove_tokens\", inputs=inputs\\n    )\\n\\n    def parse_date(_text: str):\\n\\n        text = _text\\n        if min_pos:\\n            try:\\n                text = text[min_pos:]  # type: ignore\\n            except Exception:\\n                return None\\n        if max_pos:\\n            try:\\n                text = text[0 : max_pos - min_pos]  # type: ignore  # noqa\\n            except Exception:\\n                pass\\n\\n        if remove_tokens:\\n            for t in remove_tokens:\\n                text = text.replace(t, \" \")\\n\\n        try:\\n            d_obj = parser.parse(text, fuzzy=True)\\n        except Exception as e:\\n            if force_non_null:\\n                raise KiaraProcessingException(e)\\n            return None\\n\\n        if d_obj is None:\\n            if force_non_null:\\n                raise KiaraProcessingException(\\n                    f\"Can\\'t parse date from string: {text}\"\\n                )\\n            return None\\n\\n        return d_obj\\n\\n    value = inputs.get_value_obj(\"array\")\\n    array: KiaraArray = value.data\\n\\n    series = pl.Series(name=\"tokens\", values=array.arrow_array)\\n    job_log.add_log(f\"start parsing date for {len(array)} items\")\\n    result = series.apply(parse_date)\\n    job_log.add_log(f\"finished parsing date for {len(array)} items\")\\n    result_array = result.to_arrow()\\n\\n    # TODO: remove this cast once the array data type can handle non-chunked arrays\\n    chunked = pa.chunked_array(result_array)\\n    outputs.set_values(date_array=chunked)\\n',\n",
       "   'config': {'python_class': {'python_class_name': 'ExtractDateConfig',\n",
       "     'python_module_name': 'kiara_plugin.tabular.modules.array',\n",
       "     'full_name': 'kiara_plugin.tabular.modules.array.ExtractDateConfig'},\n",
       "    'config_values': {'constants': {'description': 'Value constants for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'defaults': {'description': 'Value defaults for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'add_inputs': {'description': \"If set to 'True', parse options will be available as inputs.\",\n",
       "      'type': 'boolean',\n",
       "      'value_default': True,\n",
       "      'required': False},\n",
       "     'input_fields': {'description': 'If not empty, only add the fields specified in here to the module inputs schema.',\n",
       "      'type': 'array',\n",
       "      'value_default': [],\n",
       "      'required': False},\n",
       "     'force_non_null': {'description': \"If set to 'True', raise an error if any of the strings in the array can't be parsed.\",\n",
       "      'type': 'boolean',\n",
       "      'value_default': True,\n",
       "      'required': False},\n",
       "     'min_index': {'description': 'The minimum index from where to start parsing the string(s).',\n",
       "      'type': 'integer',\n",
       "      'value_default': None,\n",
       "      'required': False},\n",
       "     'max_index': {'description': 'The maximum index until whic to parse the string(s).',\n",
       "      'type': 'integer',\n",
       "      'value_default': None,\n",
       "      'required': False},\n",
       "     'remove_tokens': {'description': 'A list of tokens/characters to replace with a single white-space before parsing the input.',\n",
       "      'type': 'array',\n",
       "      'value_default': [],\n",
       "      'required': False}}}}},\n",
       " 16: {'id': 'module:zdpuB19zscMvy4C9ETug9tGkHsTZ3a3N9FHY8htZS1UaPCX3c',\n",
       "  'desc': {'module_type': 'table.cut_column',\n",
       "   'module_config': {'constants': {}, 'defaults': {}},\n",
       "   'label': 'table.cut_column',\n",
       "   'node_type': 'operation',\n",
       "   'level': 15},\n",
       "  'parentIds': ['value:0b8ee78f-921f-4479-b2d1-1e760f826875',\n",
       "   'module:zdpuAkfC7c35pp8SAfCx7Xmk1G1RQMvEymq4mvjDk47e1H9XN'],\n",
       "  'info': {'type_name': 'table.cut_column',\n",
       "   'documentation': {'description': 'Cut off one column from a table, returning an array.',\n",
       "    'doc': None},\n",
       "   'authors': {'authors': [{'name': 'Markus Binsteiner',\n",
       "      'email': 'markus@frkl.io'}]},\n",
       "   'context': {'references': {'source_repo': {'url': AnyUrl('https://github.com/DHARPA-Project/kiara_plugin.tabular', scheme='https', host='github.com', tld='com', host_type='domain', path='/DHARPA-Project/kiara_plugin.tabular'),\n",
       "      'desc': 'The module package git repository.'},\n",
       "     'documentation': {'url': AnyUrl('https://DHARPA-Project.github.io/kiara_plugin.tabular/', scheme='https', host='DHARPA-Project.github.io', tld='io', host_type='domain', path='/kiara_plugin.tabular/'),\n",
       "      'desc': 'The url for the module package documentation.'}},\n",
       "    'tags': ['tabular'],\n",
       "    'labels': {'package': 'kiara_plugin.tabular'}},\n",
       "   'python_class': {'python_class_name': 'CutColumnModule',\n",
       "    'python_module_name': 'kiara_plugin.tabular.modules.table',\n",
       "    'full_name': 'kiara_plugin.tabular.modules.table.CutColumnModule'},\n",
       "   'process_src': 'def process(self, inputs: ValueMap, outputs: ValueMap) -> None:\\n\\n    import pyarrow as pa\\n\\n    column_name: str = inputs.get_value_data(\"column_name\")\\n\\n    table_value: Value = inputs.get_value_obj(\"table\")\\n    table_metadata: KiaraTableMetadata = table_value.get_property_data(\\n        \"metadata.table\"\\n    )\\n\\n    available = table_metadata.table.column_names\\n\\n    if column_name not in available:\\n        raise KiaraProcessingException(\\n            f\"Invalid column name \\'{column_name}\\'. Available column names: {\\', \\'.join(available)}\"\\n        )\\n\\n    table: pa.Table = table_value.data.arrow_table\\n    column = table.column(column_name)\\n\\n    outputs.set_value(\"array\", column)\\n',\n",
       "   'config': {'python_class': {'python_class_name': 'KiaraModuleConfig',\n",
       "     'python_module_name': 'kiara.models.module',\n",
       "     'full_name': 'kiara.models.module.KiaraModuleConfig'},\n",
       "    'config_values': {'constants': {'description': 'Value constants for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'defaults': {'description': 'Value defaults for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False}}}}},\n",
       " 17: {'id': 'value:0b8ee78f-921f-4479-b2d1-1e760f826875',\n",
       "  'desc': {'label': 'column_name (string)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'string',\n",
       "   'data_type_config': {},\n",
       "   'level': 16},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': 'file_name'}},\n",
       " 18: {'id': 'module:zdpuAkfC7c35pp8SAfCx7Xmk1G1RQMvEymq4mvjDk47e1H9XN',\n",
       "  'desc': {'module_type': 'create.table',\n",
       "   'module_config': {'constants': {},\n",
       "    'defaults': {},\n",
       "    'source_type': 'text_file_bundle',\n",
       "    'target_type': 'table',\n",
       "    'ignore_errors': False},\n",
       "   'label': 'create.table',\n",
       "   'node_type': 'operation',\n",
       "   'level': 13},\n",
       "  'parentIds': ['module:zdpuAvtJAAff57xASJxvSmQ6w7SRS9W4wPQfUVftGcZAjtQdD'],\n",
       "  'info': {'type_name': 'create.table',\n",
       "   'documentation': {'description': '-- n/a --', 'doc': None},\n",
       "   'authors': {'authors': [{'name': 'Markus Binsteiner',\n",
       "      'email': 'markus@frkl.io'}]},\n",
       "   'context': {'references': {'source_repo': {'url': AnyUrl('https://github.com/DHARPA-Project/kiara_plugin.tabular', scheme='https', host='github.com', tld='com', host_type='domain', path='/DHARPA-Project/kiara_plugin.tabular'),\n",
       "      'desc': 'The module package git repository.'},\n",
       "     'documentation': {'url': AnyUrl('https://DHARPA-Project.github.io/kiara_plugin.tabular/', scheme='https', host='DHARPA-Project.github.io', tld='io', host_type='domain', path='/kiara_plugin.tabular/'),\n",
       "      'desc': 'The url for the module package documentation.'}},\n",
       "    'tags': ['tabular'],\n",
       "    'labels': {'package': 'kiara_plugin.tabular'}},\n",
       "   'python_class': {'python_class_name': 'CreateTableModule',\n",
       "    'python_module_name': 'kiara_plugin.tabular.modules.table',\n",
       "    'full_name': 'kiara_plugin.tabular.modules.table.CreateTableModule'},\n",
       "   'process_src': 'def process(self, inputs: ValueMap, outputs: ValueMap) -> None:\\n\\n    source_type = self.get_config_value(\"source_type\")\\n    target_type = self.get_config_value(\"target_type\")\\n\\n    func_name = f\"create__{target_type}__from__{source_type}\"\\n    func = getattr(self, func_name)\\n\\n    source_value = inputs.get_value_obj(source_type)\\n\\n    signature = inspect.signature(func)\\n    if \"optional\" in signature.parameters:\\n        optional: Dict[str, Value] = {}\\n        op_schemas = {}\\n        for field, schema in self.inputs_schema.items():\\n            if field == source_type:\\n                continue\\n            optional[field] = inputs.get_value_obj(field)\\n            op_schemas[field] = schema\\n        result = func(\\n            source_value=source_value,\\n            optional=ValueMapReadOnly(\\n                value_items=optional, values_schema=op_schemas\\n            ),\\n        )\\n    else:\\n        result = func(source_value=source_value)\\n    outputs.set_value(target_type, result)\\n',\n",
       "   'config': {'python_class': {'python_class_name': 'CreateTableModuleConfig',\n",
       "     'python_module_name': 'kiara_plugin.tabular.modules.table',\n",
       "     'full_name': 'kiara_plugin.tabular.modules.table.CreateTableModuleConfig'},\n",
       "    'config_values': {'constants': {'description': 'Value constants for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'defaults': {'description': 'Value defaults for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'source_type': {'description': 'The value type of the source value.',\n",
       "      'type': 'string',\n",
       "      'value_default': None,\n",
       "      'required': True},\n",
       "     'target_type': {'description': 'The value type of the target.',\n",
       "      'type': 'string',\n",
       "      'value_default': None,\n",
       "      'required': True},\n",
       "     'ignore_errors': {'description': 'Whether to ignore convert errors and omit the failed items.',\n",
       "      'type': 'boolean',\n",
       "      'value_default': False,\n",
       "      'required': False}}}}},\n",
       " 19: {'id': 'module:zdpuAvtJAAff57xASJxvSmQ6w7SRS9W4wPQfUVftGcZAjtQdD',\n",
       "  'desc': {'module_type': 'import.file_bundle',\n",
       "   'module_config': {'constants': {}, 'defaults': {}},\n",
       "   'label': 'import.file_bundle',\n",
       "   'node_type': 'operation',\n",
       "   'level': 15},\n",
       "  'parentIds': ['value:1d1776f3-239f-4db7-b3dd-7d408bcd0302'],\n",
       "  'info': {'type_name': 'import.file_bundle',\n",
       "   'documentation': {'description': 'Import a folder (file_bundle) from the local filesystem.',\n",
       "    'doc': None},\n",
       "   'authors': {'authors': [{'name': 'Markus Binsteiner',\n",
       "      'email': 'markus@frkl.io'}]},\n",
       "   'context': {'references': {'source_repo': {'url': AnyUrl('https://github.com/DHARPA-Project/kiara', scheme='https', host='github.com', tld='com', host_type='domain', path='/DHARPA-Project/kiara'),\n",
       "      'desc': 'The kiara project git repository.'},\n",
       "     'documentation': {'url': AnyUrl('https://dharpa.org/kiara_documentation/', scheme='https', host='dharpa.org', tld='org', host_type='domain', path='/kiara_documentation/'),\n",
       "      'desc': 'The url for kiara documentation.'}},\n",
       "    'tags': [],\n",
       "    'labels': {'package': 'kiara'}},\n",
       "   'python_class': {'python_class_name': 'ImportFileBundleModule',\n",
       "    'python_module_name': 'kiara.modules.included_core_modules.filesystem',\n",
       "    'full_name': 'kiara.modules.included_core_modules.filesystem.ImportFileBundleModule'},\n",
       "   'process_src': 'def process(self, inputs: ValueMap, outputs: ValueMap):\\n\\n    path = inputs.get_value_data(\"path\")\\n\\n    file_bundle = FileBundle.import_folder(source=path)\\n    outputs.set_value(\"file_bundle\", file_bundle)\\n',\n",
       "   'config': {'python_class': {'python_class_name': 'KiaraModuleConfig',\n",
       "     'python_module_name': 'kiara.models.module',\n",
       "     'full_name': 'kiara.models.module.KiaraModuleConfig'},\n",
       "    'config_values': {'constants': {'description': 'Value constants for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False},\n",
       "     'defaults': {'description': 'Value defaults for this module.',\n",
       "      'type': 'object',\n",
       "      'value_default': {},\n",
       "      'required': False}}}}},\n",
       " 20: {'id': 'value:1d1776f3-239f-4db7-b3dd-7d408bcd0302',\n",
       "  'desc': {'label': 'path (string)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'string',\n",
       "   'data_type_config': {},\n",
       "   'level': 16},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': '/Users/mariella.decrouychan/Documents/GitHub/DHARPA-Project-viz-observable/dag-lineage/example_data/mini_corpus'}},\n",
       " 21: {'id': 'value:9bf6c998-9d8b-4571-ac92-a7e3d8d87892',\n",
       "  'desc': {'label': 'max_index (integer)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'integer',\n",
       "   'data_type_config': {},\n",
       "   'level': 14},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': '21'}},\n",
       " 22: {'id': 'value:ebfb1534-cef9-400c-9fdb-59c5d2f6302f',\n",
       "  'desc': {'label': 'min_index (integer)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'integer',\n",
       "   'data_type_config': {},\n",
       "   'level': 14},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': '11'}},\n",
       " 23: {'id': 'value:5704a550-4f4c-44b2-95f3-bf25364a41ee',\n",
       "  'desc': {'label': 'words_per_topic (integer)',\n",
       "   'node_type': 'value',\n",
       "   'data_type': 'integer',\n",
       "   'data_type_config': {},\n",
       "   'level': 4},\n",
       "  'parentIds': [],\n",
       "  'info': {'preview': '10'}}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #uncomment to export dataset for the viz\n",
    "# res = json.dumps(augmented_nodes)\n",
    "# with open(\"lineage_data_2.json\", \"w\") as outfile:\n",
    "#     outfile.write(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('lineage2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f265ba5b95a3c2043dd2c2733d8b8da7ea94a198ff1570b6a032f3ce989fb484"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
